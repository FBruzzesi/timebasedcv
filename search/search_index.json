{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#timebased-cross-validation","title":"Timebased Cross Validation","text":"<p>timebasedcv is a Python codebase that provides a cross validation strategy based on time.</p> <p>Documentation | Repository | Issue Tracker</p>"},{"location":"#disclaimer","title":"Disclaimer \u26a0\ufe0f","text":"<p>This codebase is experimental and is working for my use cases. It is very probable that there are cases not entirely covered and for which it could break (badly). If you find them, please feel free to open an issue in the issue page of the repo.</p>"},{"location":"#description","title":"Description \u2728","text":"<p>The current implementation of scikit-learn TimeSeriesSplit lacks the flexibility of having multiple samples within the same time period (or time unit).</p> <p>timebasedcv addresses such problem by providing a cross validation strategy based on a time period rather than the number of samples. This is useful when the data is time dependent, and the split should keep together samples within the same time window.</p> <p>Temporal data leakage is an issue and we want to prevent it from happening by providing splits that make sure the past and the future are well separated, so that data leakage does not spoil in a model cross validation.</p> <p>Again, these splits points solely depend on the time period and not the number of observations.</p>"},{"location":"#features","title":"Features \ud83d\udcdc","text":"<p>We introduce two main classes:</p> <ul> <li> <p><code>TimeBasedSplit</code> allows to define a split based on time unit (frequency), train size, test size, gap, stride, window type and mode.</p> <p>Warning</p> <p><code>TimeBasedSplit</code> is not compatible with scikit-learn CV Splitters.</p> <p>In fact, we have made the (opinioned) choice to:</p> <ul> <li>Return the sliced arrays from <code>.split(...)</code>, while scikit-learn CV Splitters return train and test indices of the split.</li> <li>Require to pass the time series as input to <code>.split(...)</code> method, while scikit-learn CV Splitters require to provide only <code>X, y, groups</code> to <code>.split(...)</code>.</li> <li>Such time series is used to generate the boolean masks with which we slice the original arrays into train and test for each split.</li> </ul> </li> <li> <p>Considering the above choices, we also provide a scikit-learn compatible splitter: <code>TimeBasedCVSplitter</code>. Considering the signature that <code>.split(...)</code> requires and the fact that CV Splitters need to know a priori the number of splits, <code>TimeBasedCVSplitter</code> is initialized with the time series containing the time information used to generate the train and test indices of each split.</p> </li> </ul>"},{"location":"#dataframe-and-array-agnostic","title":"Dataframe and array agnostic","text":"<ul> <li>Thanks to Narwhals, <code>TimeBasedSplit</code> works out of the box with <code>pandas</code>, <code>polars</code>, <code>pyarrow</code> and any other dataframe library supported by Narwhals.</li> <li>Thanks to the array API, <code>TimeBasedSplit</code> works out of the box with <code>numpy</code>, <code>cupy</code>, <code>dask.array</code> and any other array library that support slicing \u00e0 la numpy.</li> </ul>"},{"location":"#installation","title":"Installation \ud83d\udcbb","text":"<p>TL;DR:</p> <pre><code>python -m pip install timebasedcv\n</code></pre> <p>For further information, please refer to the dedicated installation section.</p>"},{"location":"#getting-started","title":"Getting Started \ud83c\udfc3","text":"<p>Please refer to the dedicated getting started section.</p>"},{"location":"#contributing","title":"Contributing \u270c\ufe0f","text":"<p>Please refer to the dedicated contributing guidelines section.</p>"},{"location":"#license","title":"License \ud83d\udc40","text":"<p>The project has a MIT Licence.</p>"},{"location":"contribute/","title":"Contributing \ud83d\udc4f","text":""},{"location":"contribute/#guidelines","title":"Guidelines \ud83d\udca1","text":"<p>We welcome contributions to the library! If you have a bug fix or new feature that you would like to contribute, please follow the steps below:</p> <ol> <li>Check the existing issues and/or open a new one to discuss the problem and potential solutions.</li> <li>Fork the repository on GitHub.</li> <li>Clone the repository to your local machine.</li> <li>Create a new branch for your bug fix or feature.</li> <li>Make your changes and test them thoroughly, making sure that it passes all current tests.</li> <li>Commit your changes and push the branch to your fork.</li> <li>Open a pull request on the main repository.</li> </ol>"},{"location":"contribute/#submitting-pull-requests","title":"Submitting Pull Requests \ud83c\udfaf","text":"<p>When submitting a pull request, please make sure that you've followed the steps above and that your code has been thoroughly tested. Also, be sure to include a brief summary of the changes you've made and a reference to any issues that your pull request resolves.</p>"},{"location":"contribute/#code-formatting","title":"Code formatting \ud83d\ude80","text":"<p>timebasedcv uses ruff for both formatting and linting. Specific settings are declared in the pyproject.toml file.</p> <p>To format the code, you can run the following commands:</p> with Makewithout Make <pre><code>make lint\n</code></pre> <pre><code>ruff version\nruff format timebasedcv tests\nruff check timebasedcv tests --fix\nruff clean\n</code></pre> <p>As part of the checks on pull requests, it is checked whether the code follows those standards. To ensure that the standard is met, it is recommended to install pre-commit hooks:</p> <pre><code>python -m pip install pre-commit\npre-commit install\n</code></pre>"},{"location":"contribute/#developing","title":"Developing \ud83d\udc0d","text":"<p>Let's suppose that you already did steps 1-4 from the above list, now you should install the library and its developing dependencies  in editable way.</p> <p>First move into the repo folder: <code>cd timebasedcv</code>.</p> <p>Then:</p> with Makewithout Make <pre><code>make init-dev\n</code></pre> <pre><code>pip install -e \".[all-dev]\" --no-cache-dir\npre-commit install\n</code></pre> <p>Now you are ready to proceed with all the changes you want to!</p>"},{"location":"contribute/#testing","title":"Testing \ud83e\uddea","text":"<p>Once you are done with changes, you should:</p> <ul> <li>add tests for the new features in the <code>/tests</code> folder</li> <li> <p>make sure that new features do not break existing codebase by running tests:</p> with Makewithout Make <pre><code>make test\n</code></pre> <pre><code>pytest tests -n auto\n</code></pre> </li> </ul>"},{"location":"contribute/#docs","title":"Docs \ud83d\udcd1","text":"<p>The documentation is generated using mkdocs-material, the API part uses mkdocstrings.</p> <p>If a new feature or a breaking change is developed, then we suggest to update documentation in the <code>/docs</code> folder as well, in order to describe how this can be used from a user perspective.</p>"},{"location":"installation/","title":"Installation \ud83d\udcbb","text":"<p>timebasedcv is a published Python package on pypi, therefore it can be installed directly via pip, as well as from source using pip and git, or with a local clone:</p> pip (suggested)pip + source/gitlocal clone <pre><code>python -m pip install timebasedcv\n</code></pre> <pre><code>python -m pip install git+https://github.com/FBruzzesi/timebasedcv.git\n</code></pre> <pre><code>git clone https://github.com/FBruzzesi/timebasedcv.git\ncd timebasedcv\npython -m pip install .\n</code></pre>"},{"location":"installation/#dependencies","title":"Dependencies \ud83d\udc4f","text":"<p>Info</p> <p>The minimum Python version supported is 3.8.</p> <ul> <li> <p>Since v0.1.0, the only two dependencies are <code>numpy</code> and <code>narwhals&gt;=1.0.0</code>.</p> <p>Narwhals allows to have a compatibility layer between polars, pandas and other dataframe libraries. Therefore, as long as narwhals supports such dataframe object, we will as well.</p> </li> <li> <p>Since v0.2.0, in order to use <code>TimeBasedCVSplitter</code>, <code>scikit-learn&gt;=0.19</code> is required, nevertheless it is not a direct dependency of the package.</p> </li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>The API reference is automatically generated from the docstrings in the code. The following sections are available:</p> <ul> <li>timebasedcv</li> <li>timebasedcv.core</li> <li>timebasedcv.sklearn</li> <li>timebasedcv.splitstate</li> </ul>"},{"location":"api/core/","title":"<code>timebasedcv.core</code>","text":""},{"location":"api/core/#timebasedcv.core._CoreTimeBasedSplit","title":"timebasedcv.core._CoreTimeBasedSplit","text":"<p>Base class for time based splits. This class is not meant to be used directly.</p> <p><code>_CoreTimeBasedSplit</code> implements all the logics to set up a time based splits class.</p> <p>In particular it implements <code>_splits_from_period</code> which is used to generate splits from a given time period (from start to end dates) from the given arguments of the class (frequency, train_size, forecast_horizon, gap, stride and window type).</p> <p>Parameters:</p> Name Type Description Default <code>frequency</code> <code>FrequencyUnit</code> <p>The frequency (or time unit) of the time series. Must be one of \"days\", \"seconds\", \"microseconds\", \"milliseconds\", \"minutes\", \"hours\", \"weeks\", \"months\" or \"years\". These are the valid values for the <code>unit</code> argument of <code>relativedelta</code> from python <code>dateutil</code> library.</p> required <code>train_size</code> <code>int</code> <p>Defines the minimum number of time units required to be in the train set.</p> required <code>forecast_horizon</code> <code>int</code> <p>Specifies the number of time units to forecast.</p> required <code>gap</code> <code>int</code> <p>Sets the number of time units to skip between the end of the train set and the start of the forecast set.</p> <code>0</code> <code>stride</code> <code>int | None</code> <p>How many time unit to move forward after each split. If <code>None</code> (or set to 0), the stride is equal to the <code>forecast_horizon</code> quantity.</p> <code>None</code> <code>window</code> <code>WindowType</code> <p>The type of window to use, either \"rolling\" or \"expanding\".</p> <code>'rolling'</code> <code>mode</code> <code>ModeType</code> <p>Determines in which orders the splits are generated, either \"forward\" (start to end) or \"backward\" (end to start).</p> <code>'forward'</code> <p>Raises:</p> Type Description <code>ValueError</code> <ul> <li>If <code>frequency</code> is not one of \"days\", \"seconds\", \"microseconds\", \"milliseconds\", \"minutes\", \"hours\", \"weeks\".</li> <li>If <code>window</code> is not one of \"rolling\" or \"expanding\".</li> <li>If <code>mode</code> is not one of \"forward\" or \"backward\"</li> <li>If <code>train_size</code>, <code>forecast_horizon</code>, <code>gap</code> or <code>stride</code> are not strictly positive.</li> </ul> <code>TypeError</code> <p>If <code>train_size</code>, <code>forecast_horizon</code>, <code>gap</code> or <code>stride</code> are not of type <code>int</code>.</p> <p>Although <code>_CoreTimeBasedSplit</code> is not meant to be used directly, it can be used as a template to create new time based splits classes.</p> <p>Examples:</p> <pre><code>from timebasedcv.core import _CoreTimeBasedSplit\n\n\nclass MyTimeBasedSplit(_CoreTimeBasedSplit):\n    ...\n\n    def split(self, X, timeseries):\n        '''Implement the split method to return a generator'''\n\n        for split in self._splits_from_period(timeseries.min(), timeseries.max()):\n            # Do something with the split to compute the train and forecast sets\n            ...\n            yield X_train, y_test\n</code></pre> Source code in <code>timebasedcv/core.py</code> <pre><code>class _CoreTimeBasedSplit:\n    \"\"\"Base class for time based splits. This class is not meant to be used directly.\n\n    `_CoreTimeBasedSplit` implements all the logics to set up a time based splits class.\n\n    In particular it implements `_splits_from_period` which is used to generate splits from a given time period (from\n    start to end dates) from the given arguments of the class (frequency, train_size, forecast_horizon, gap, stride and\n    window type).\n\n    Arguments:\n        frequency: The frequency (or time unit) of the time series. Must be one of \"days\", \"seconds\", \"microseconds\",\n            \"milliseconds\", \"minutes\", \"hours\", \"weeks\", \"months\" or \"years\". These are the valid values for the\n            `unit` argument of `relativedelta` from python `dateutil` library.\n        train_size: Defines the minimum number of time units required to be in the train set.\n        forecast_horizon: Specifies the number of time units to forecast.\n        gap: Sets the number of time units to skip between the end of the train set and the start of the forecast set.\n        stride: How many time unit to move forward after each split. If `None` (or set to 0), the stride is equal to the\n            `forecast_horizon` quantity.\n        window: The type of window to use, either \"rolling\" or \"expanding\".\n        mode: Determines in which orders the splits are generated, either \"forward\" (start to end) or \"backward\"\n            (end to start).\n\n    Raises:\n        ValueError:\n            - If `frequency` is not one of \"days\", \"seconds\", \"microseconds\", \"milliseconds\", \"minutes\", \"hours\",\n            \"weeks\".\n            - If `window` is not one of \"rolling\" or \"expanding\".\n            - If `mode` is not one of \"forward\" or \"backward\"\n            - If `train_size`, `forecast_horizon`, `gap` or `stride` are not strictly positive.\n        TypeError: If `train_size`, `forecast_horizon`, `gap` or `stride` are not of type `int`.\n\n    Although `_CoreTimeBasedSplit` is not meant to be used directly, it can be used as a template to create new time\n    based splits classes.\n\n    Examples:\n        ```python\n        from timebasedcv.core import _CoreTimeBasedSplit\n\n\n        class MyTimeBasedSplit(_CoreTimeBasedSplit):\n            ...\n\n            def split(self, X, timeseries):\n                '''Implement the split method to return a generator'''\n\n                for split in self._splits_from_period(timeseries.min(), timeseries.max()):\n                    # Do something with the split to compute the train and forecast sets\n                    ...\n                    yield X_train, y_test\n        ```\n    \"\"\"\n\n    def __init__(  # noqa: PLR0913\n        self: Self,\n        *,\n        frequency: FrequencyUnit,\n        train_size: int,\n        forecast_horizon: int,\n        gap: int = 0,\n        stride: int | None = None,\n        window: WindowType = \"rolling\",\n        mode: ModeType = \"forward\",\n    ) -&gt; None:\n        self.frequency_ = frequency\n        self.train_size_ = train_size\n        self.forecast_horizon_ = forecast_horizon\n        self.gap_ = gap\n        self.stride_ = stride or forecast_horizon\n        self.window_ = window\n        self.mode_ = mode\n\n        self._validate_arguments()\n\n    def _validate_arguments(self: Self) -&gt; None:\n        \"\"\"Post init used to validate the TimeSpacedSplit attributes.\"\"\"\n        # Validate frequency\n        if self.frequency_ not in _frequency_values:\n            msg = f\"`frequency` must be one of {_frequency_values}. Found {self.frequency_}\"\n            raise ValueError(msg)\n\n        # Validate window\n        if self.window_ not in _window_values:\n            msg = f\"`window` must be one of {_window_values}. Found {self.window_}\"\n            raise ValueError(msg)\n\n        # Validate mode\n        if self.mode_ not in _mode_values:\n            msg = f\"`mode` must be one of {_mode_values}. Found {self.mode_}\"\n            raise ValueError(msg)\n\n        # Validate positive integer arguments\n        _slot_names = (\"train_size_\", \"forecast_horizon_\", \"gap_\", \"stride_\")\n        _values = tuple(getattr(self, _attr) for _attr in _slot_names)\n        _lower_bounds = (1, 1, 0, 1)\n\n        _types = tuple(type(v) for v in _values)\n\n        if not all(t is int for t in _types):\n            msg = (\n                f\"(`{'`, `'.join(_slot_names)}`) arguments must be of type `int`. \"\n                f\"Found (`{'`, `'.join(str(t) for t in _types)}`)\"\n            )\n            raise TypeError(msg)\n\n        if not all(v &gt;= lb for v, lb in zip(_values, _lower_bounds)):\n            msg = (\n                f\"(`{'`, `'.join(_slot_names)}`) must be greater or equal than \"\n                f\"({', '.join(map(str, _lower_bounds))}).\\n\"\n                f\"Found ({', '.join(str(v) for v in _values)})\"\n            )\n            raise ValueError(msg)\n\n    @property\n    def name_(self: Self) -&gt; str:\n        return self.__class__.__name__\n\n    def __repr__(self: Self) -&gt; str:\n        \"\"\"Custom repr method.\"\"\"\n        _attrs = (\n            \"frequency_\",\n            \"train_size_\",\n            \"forecast_horizon_\",\n            \"gap_\",\n            \"stride_\",\n            \"window_\",\n        )\n        _values = tuple(getattr(self, _attr) for _attr in _attrs)\n        _new_line_tab = \"\\n    \"\n\n        return f\"{self.name_}(\\n    {_new_line_tab.join(f'{s} = {v}' for s, v in zip(_attrs, _values))}\\n)\"\n\n    @property\n    def train_delta(self: Self) -&gt; relativedelta:\n        \"\"\"Returns the `relativedelta` object corresponding to the `train_size`.\"\"\"\n        return relativedelta(**{str(self.frequency_): self.train_size_})  # type: ignore[arg-type]\n\n    @property\n    def forecast_delta(self: Self) -&gt; relativedelta:\n        \"\"\"Returns the `relativedelta` object corresponding to the `forecast_horizon`.\"\"\"\n        return relativedelta(**{str(self.frequency_): self.forecast_horizon_})  # type: ignore[arg-type]\n\n    @property\n    def gap_delta(self: Self) -&gt; relativedelta:\n        \"\"\"Returns the `relativedelta` object corresponding to the `gap` and `frequency`.\"\"\"\n        return relativedelta(**{str(self.frequency_): self.gap_})  # type: ignore[arg-type]\n\n    @property\n    def stride_delta(self: Self) -&gt; relativedelta:\n        \"\"\"Returns the `relativedelta` object corresponding to `stride`.\"\"\"\n        return relativedelta(**{str(self.frequency_): self.stride_})  # type: ignore[arg-type]\n\n    def _splits_from_period(\n        self: Self,\n        time_start: DateTimeLike,\n        time_end: DateTimeLike,\n    ) -&gt; Generator[SplitState, None, None]:\n        \"\"\"Generate splits from `time_start` to `time_end` based on the parameters passed to the class instance.\n\n        This is the core iteration that generates splits. It is used by the `split` method to generate splits from the\n        time series.\n\n        Arguments:\n            time_start: The start of the time period.\n            time_end: The end of the time period.\n\n        Returns:\n            A generator of `SplitState` instances.\n        \"\"\"\n        if time_start &gt;= time_end:\n            msg = \"`time_start` must be before `time_end`.\"\n            raise ValueError(msg)\n\n        is_rolling_window = self.window_ == \"rolling\"\n\n        if self.mode_ == \"forward\":\n            train_delta = self.train_delta\n            forecast_delta = self.forecast_delta\n            gap_delta = self.gap_delta\n            stride_delta = self.stride_delta\n\n            train_start = time_start\n            train_end = time_start + train_delta\n            forecast_start = train_end + gap_delta\n            forecast_end = forecast_start + forecast_delta\n\n        else:\n            train_delta = -self.train_delta\n            forecast_delta = -self.forecast_delta\n            gap_delta = -self.gap_delta\n            stride_delta = -self.stride_delta\n\n            forecast_end = time_end\n            forecast_start = forecast_end + forecast_delta\n            train_end = forecast_start + gap_delta\n            train_start = train_end + train_delta if is_rolling_window else time_start\n\n        while (forecast_start &lt;= time_end) and (train_start &gt;= time_start) and (train_start &lt;= train_end + train_delta):\n            yield SplitState(train_start, train_end, forecast_start, forecast_end)\n\n            # Update state values\n            train_start = train_start + stride_delta if is_rolling_window else train_start\n            train_end = train_end + stride_delta\n            forecast_start = forecast_start + stride_delta\n            forecast_end = forecast_end + stride_delta\n\n    def n_splits_of(\n        self: Self,\n        *,\n        time_series: SeriesLike[DateTimeLike] | None = None,\n        start_dt: NullableDatetime = None,\n        end_dt: NullableDatetime = None,\n    ) -&gt; int:\n        \"\"\"Returns the number of splits that can be generated from `time_series`.\n\n        Arguments:\n            time_series: A time series data. If provided it should support `.min()` and `.max().\n            start_dt: The start date and time of the time series. If not provided, it will be inferred from\n                `time_series`.\n            end_dt: The end date and time of the time series. If not provided, it will be inferred from\n                `time_series`.\n\n        Returns:\n            The number of splits that can be generated from the given time series.\n\n        Raises:\n            ValueError:\n                - If both `start_dt` and `end_dt` are provided and `start_dt` is greater than or equal to `end_dt`.\n                - If neither `time_series` nor (`start_dt`, `end_dt`) pair is provided.\n        \"\"\"\n        if (start_dt is not None) and (end_dt is not None):\n            if start_dt &gt;= end_dt:\n                msg = \"`start_dt` must be before `end_dt`.\"\n                raise ValueError(msg)\n            else:\n                time_start, time_end = start_dt, end_dt\n        elif time_series is not None:\n            time_start, time_end = time_series.min(), time_series.max()\n        else:\n            msg = \"Either `time_series` or (`start_dt`, `end_dt`) pair must be provided.\"\n            raise ValueError(msg)\n\n        return len(tuple(self._splits_from_period(time_start, time_end)))\n</code></pre>"},{"location":"api/core/#timebasedcv.core._CoreTimeBasedSplit.forecast_delta","title":"forecast_delta  <code>property</code>","text":"<pre><code>forecast_delta: relativedelta\n</code></pre> <p>Returns the <code>relativedelta</code> object corresponding to the <code>forecast_horizon</code>.</p>"},{"location":"api/core/#timebasedcv.core._CoreTimeBasedSplit.gap_delta","title":"gap_delta  <code>property</code>","text":"<pre><code>gap_delta: relativedelta\n</code></pre> <p>Returns the <code>relativedelta</code> object corresponding to the <code>gap</code> and <code>frequency</code>.</p>"},{"location":"api/core/#timebasedcv.core._CoreTimeBasedSplit.stride_delta","title":"stride_delta  <code>property</code>","text":"<pre><code>stride_delta: relativedelta\n</code></pre> <p>Returns the <code>relativedelta</code> object corresponding to <code>stride</code>.</p>"},{"location":"api/core/#timebasedcv.core._CoreTimeBasedSplit.train_delta","title":"train_delta  <code>property</code>","text":"<pre><code>train_delta: relativedelta\n</code></pre> <p>Returns the <code>relativedelta</code> object corresponding to the <code>train_size</code>.</p>"},{"location":"api/core/#timebasedcv.core._CoreTimeBasedSplit.__repr__","title":"__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> <p>Custom repr method.</p> Source code in <code>timebasedcv/core.py</code> <pre><code>def __repr__(self: Self) -&gt; str:\n    \"\"\"Custom repr method.\"\"\"\n    _attrs = (\n        \"frequency_\",\n        \"train_size_\",\n        \"forecast_horizon_\",\n        \"gap_\",\n        \"stride_\",\n        \"window_\",\n    )\n    _values = tuple(getattr(self, _attr) for _attr in _attrs)\n    _new_line_tab = \"\\n    \"\n\n    return f\"{self.name_}(\\n    {_new_line_tab.join(f'{s} = {v}' for s, v in zip(_attrs, _values))}\\n)\"\n</code></pre>"},{"location":"api/core/#timebasedcv.core._CoreTimeBasedSplit.n_splits_of","title":"n_splits_of","text":"<pre><code>n_splits_of(*, time_series: SeriesLike[DateTimeLike] | None = None, start_dt: NullableDatetime = None, end_dt: NullableDatetime = None) -&gt; int\n</code></pre> <p>Returns the number of splits that can be generated from <code>time_series</code>.</p> <p>Parameters:</p> Name Type Description Default <code>time_series</code> <code>SeriesLike[DateTimeLike] | None</code> <p>A time series data. If provided it should support <code>.min()</code> and `.max().</p> <code>None</code> <code>start_dt</code> <code>NullableDatetime</code> <p>The start date and time of the time series. If not provided, it will be inferred from <code>time_series</code>.</p> <code>None</code> <code>end_dt</code> <code>NullableDatetime</code> <p>The end date and time of the time series. If not provided, it will be inferred from <code>time_series</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>The number of splits that can be generated from the given time series.</p> <p>Raises:</p> Type Description <code>ValueError</code> <ul> <li>If both <code>start_dt</code> and <code>end_dt</code> are provided and <code>start_dt</code> is greater than or equal to <code>end_dt</code>.</li> <li>If neither <code>time_series</code> nor (<code>start_dt</code>, <code>end_dt</code>) pair is provided.</li> </ul> Source code in <code>timebasedcv/core.py</code> <pre><code>def n_splits_of(\n    self: Self,\n    *,\n    time_series: SeriesLike[DateTimeLike] | None = None,\n    start_dt: NullableDatetime = None,\n    end_dt: NullableDatetime = None,\n) -&gt; int:\n    \"\"\"Returns the number of splits that can be generated from `time_series`.\n\n    Arguments:\n        time_series: A time series data. If provided it should support `.min()` and `.max().\n        start_dt: The start date and time of the time series. If not provided, it will be inferred from\n            `time_series`.\n        end_dt: The end date and time of the time series. If not provided, it will be inferred from\n            `time_series`.\n\n    Returns:\n        The number of splits that can be generated from the given time series.\n\n    Raises:\n        ValueError:\n            - If both `start_dt` and `end_dt` are provided and `start_dt` is greater than or equal to `end_dt`.\n            - If neither `time_series` nor (`start_dt`, `end_dt`) pair is provided.\n    \"\"\"\n    if (start_dt is not None) and (end_dt is not None):\n        if start_dt &gt;= end_dt:\n            msg = \"`start_dt` must be before `end_dt`.\"\n            raise ValueError(msg)\n        else:\n            time_start, time_end = start_dt, end_dt\n    elif time_series is not None:\n        time_start, time_end = time_series.min(), time_series.max()\n    else:\n        msg = \"Either `time_series` or (`start_dt`, `end_dt`) pair must be provided.\"\n        raise ValueError(msg)\n\n    return len(tuple(self._splits_from_period(time_start, time_end)))\n</code></pre>"},{"location":"api/sklearn/","title":"<code>timebasedcv.sklearn</code>","text":""},{"location":"api/sklearn/#timebasedcv.sklearn.TimeBasedCVSplitter","title":"timebasedcv.sklearn.TimeBasedCVSplitter","text":"<p>               Bases: <code>_BaseKFold</code></p> <p>The <code>TimeBasedCVSplitter</code> is a scikit-learn compatible CV Splitter that generates splits based on time values.</p> <p>The number of sample in each split is independent of the number of splits but based purely on the timestamp of the sample.</p> <p>In order to achieve such behaviour we include the arguments of <code>TimeBasedSplit.split()</code> method (namely <code>time_series</code>, <code>start_dt</code> and <code>end_dt</code>) in the constructor (a.k.a. <code>__init__</code> method) and store the for future use in its <code>split</code> and <code>get_n_splits</code> methods.</p> <p>In this way we can restrict the arguments of <code>split</code> and <code>get_n_splits</code> to the arrays to split (i.e. <code>X</code>, <code>y</code> and <code>groups</code>), which are the only arguments required by scikit-learn CV Splitters.</p> <p>Parameters:</p> Name Type Description Default <code>frequency</code> <code>FrequencyUnit</code> <p>The frequency (or time unit) of the time series. Must be one of \"days\", \"seconds\", \"microseconds\", \"milliseconds\", \"minutes\", \"hours\", \"weeks\", \"months\" or \"years\". These are the valid values for the <code>unit</code> argument of <code>relativedelta</code> from python <code>dateutil</code> library.</p> required <code>train_size</code> <code>int</code> <p>Defines the minimum number of time units required to be in the train set.</p> required <code>forecast_horizon</code> <code>int</code> <p>Specifies the number of time units to forecast.</p> required <code>time_series</code> <code>SeriesLike[date] | SeriesLike[datetime] | SeriesLike[Timestamp]</code> <p>The time series used to create boolean mask for splits. It is not required to be sorted, but it must support:</p> <ul> <li>comparison operators (with other date-like objects).</li> <li>bitwise operators (with other boolean arrays).</li> <li><code>.min()</code> and <code>.max()</code> methods.</li> <li><code>.shape</code> attribute.</li> </ul> required <code>gap</code> <code>int</code> <p>Sets the number of time units to skip between the end of the train set and the start of the forecast set.</p> <code>0</code> <code>stride</code> <code>int | None</code> <p>How many time unit to move forward after each split. If <code>None</code> (or set to 0), the stride is equal to the <code>forecast_horizon</code> quantity.</p> <code>None</code> <code>window</code> <code>WindowType</code> <p>The type of window to use, either \"rolling\" or \"expanding\".</p> <code>'rolling'</code> <code>mode</code> <code>ModeType</code> <p>Determines in which orders the splits are generated, either \"forward\" (start to end) or \"backward\" (end to start).</p> <code>'forward'</code> <code>start_dt</code> <code>NullableDatetime</code> <p>The start of the time period. If provided, it is used in place of the <code>time_series.min()</code>.</p> <code>None</code> <code>end_dt</code> <code>NullableDatetime</code> <p>The end of the time period. If provided,it is used in place of the <code>time_series.max()</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <ul> <li>If <code>frequency</code> is not one of \"days\", \"seconds\", \"microseconds\", \"milliseconds\", \"minutes\", \"hours\", \"weeks\".</li> <li>If <code>window</code> is not one of \"rolling\" or \"expanding\".</li> <li>If <code>mode</code> is not one of \"forward\" or \"backward\"</li> <li>If <code>train_size</code>, <code>forecast_horizon</code>, <code>gap</code> or <code>stride</code> are not strictly positive.</li> </ul> <code>TypeError</code> <p>If <code>train_size</code>, <code>forecast_horizon</code>, <code>gap</code> or <code>stride</code> are not of type <code>int</code>.</p> <p>Examples:</p> <pre><code>import pandas as pd\nimport numpy as np\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom timebasedcv.sklearn import TimeBasedCVSplitter\n\nstart_dt = pd.Timestamp(2023, 1, 1)\nend_dt = pd.Timestamp(2023, 1, 31)\n\ntime_series = pd.Series(pd.date_range(start_dt, end_dt, freq=\"D\"))\nsize = len(time_series)\n\ndf = pd.DataFrame(data=np.random.randn(size, 2), columns=[\"a\", \"b\"])\n\nX, y = df[[\"a\", \"b\"]], df[[\"a\", \"b\"]].sum(axis=1)\n\ncv = TimeBasedCVSplitter(\n    frequency=\"days\",\n    train_size=7,\n    forecast_horizon=11,\n    gap=0,\n    stride=1,\n    window=\"rolling\",\n    time_series=time_series,\n    start_dt=start_dt,\n    end_dt=end_dt,\n)\n\nparam_grid = {\n    \"alpha\": np.linspace(0.1, 2, 10),\n    \"fit_intercept\": [True, False],\n    \"positive\": [True, False],\n}\n\nrandom_search_cv = RandomizedSearchCV(\n    estimator=Ridge(),\n    param_distributions=param_grid,\n    cv=cv,\n    n_jobs=-1,\n).fit(X, y)\n</code></pre> Source code in <code>timebasedcv/sklearn.py</code> <pre><code>class TimeBasedCVSplitter(_BaseKFold):  # type: ignore[no-any-unimported]\n    \"\"\"The `TimeBasedCVSplitter` is a scikit-learn compatible CV Splitter that generates splits based on time values.\n\n    The number of sample in each split is independent of the number of splits but based purely on the timestamp of the\n    sample.\n\n    In order to achieve such behaviour we include the arguments of\n    [`TimeBasedSplit.split()`][timebasedcv.core.TimeBasedSplit.split] method (namely `time_series`, `start_dt` and\n    `end_dt`) in the constructor (a.k.a. `__init__` method) and store the for future use in its `split` and\n    `get_n_splits` methods.\n\n    In this way we can restrict the arguments of `split` and `get_n_splits` to the arrays to split (i.e. `X`, `y` and\n    `groups`), which are the only arguments required by scikit-learn CV Splitters.\n\n    Arguments:\n        frequency: The frequency (or time unit) of the time series. Must be one of \"days\", \"seconds\", \"microseconds\",\n            \"milliseconds\", \"minutes\", \"hours\", \"weeks\", \"months\" or \"years\". These are the valid values for the\n            `unit` argument of `relativedelta` from python `dateutil` library.\n        train_size: Defines the minimum number of time units required to be in the train set.\n        forecast_horizon: Specifies the number of time units to forecast.\n        time_series: The time series used to create boolean mask for splits. It is not required to be sorted, but it\n            must support:\n\n            - comparison operators (with other date-like objects).\n            - bitwise operators (with other boolean arrays).\n            - `.min()` and `.max()` methods.\n            - `.shape` attribute.\n        gap: Sets the number of time units to skip between the end of the train set and the start of the forecast set.\n        stride: How many time unit to move forward after each split. If `None` (or set to 0), the stride is equal to the\n            `forecast_horizon` quantity.\n        window: The type of window to use, either \"rolling\" or \"expanding\".\n        mode: Determines in which orders the splits are generated, either \"forward\" (start to end) or \"backward\"\n            (end to start).\n        start_dt: The start of the time period. If provided, it is used in place of the `time_series.min()`.\n        end_dt: The end of the time period. If provided,it is used in place of the `time_series.max()`.\n\n    Raises:\n        ValueError:\n            - If `frequency` is not one of \"days\", \"seconds\", \"microseconds\", \"milliseconds\", \"minutes\", \"hours\",\n            \"weeks\".\n            - If `window` is not one of \"rolling\" or \"expanding\".\n            - If `mode` is not one of \"forward\" or \"backward\"\n            - If `train_size`, `forecast_horizon`, `gap` or `stride` are not strictly positive.\n        TypeError: If `train_size`, `forecast_horizon`, `gap` or `stride` are not of type `int`.\n\n    Examples:\n        ```python\n        import pandas as pd\n        import numpy as np\n\n        from sklearn.linear_model import Ridge\n        from sklearn.model_selection import RandomizedSearchCV\n\n        from timebasedcv.sklearn import TimeBasedCVSplitter\n\n        start_dt = pd.Timestamp(2023, 1, 1)\n        end_dt = pd.Timestamp(2023, 1, 31)\n\n        time_series = pd.Series(pd.date_range(start_dt, end_dt, freq=\"D\"))\n        size = len(time_series)\n\n        df = pd.DataFrame(data=np.random.randn(size, 2), columns=[\"a\", \"b\"])\n\n        X, y = df[[\"a\", \"b\"]], df[[\"a\", \"b\"]].sum(axis=1)\n\n        cv = TimeBasedCVSplitter(\n            frequency=\"days\",\n            train_size=7,\n            forecast_horizon=11,\n            gap=0,\n            stride=1,\n            window=\"rolling\",\n            time_series=time_series,\n            start_dt=start_dt,\n            end_dt=end_dt,\n        )\n\n        param_grid = {\n            \"alpha\": np.linspace(0.1, 2, 10),\n            \"fit_intercept\": [True, False],\n            \"positive\": [True, False],\n        }\n\n        random_search_cv = RandomizedSearchCV(\n            estimator=Ridge(),\n            param_distributions=param_grid,\n            cv=cv,\n            n_jobs=-1,\n        ).fit(X, y)\n        ```\n    \"\"\"\n\n    def __init__(  # noqa: PLR0913\n        self: Self,\n        *,\n        frequency: FrequencyUnit,\n        train_size: int,\n        forecast_horizon: int,\n        time_series: SeriesLike[date] | SeriesLike[datetime] | SeriesLike[pd.Timestamp],\n        gap: int = 0,\n        stride: int | None = None,\n        window: WindowType = \"rolling\",\n        mode: ModeType = \"forward\",\n        start_dt: NullableDatetime = None,\n        end_dt: NullableDatetime = None,\n    ) -&gt; None:\n        self.splitter = TimeBasedSplit(\n            frequency=frequency,\n            train_size=train_size,\n            forecast_horizon=forecast_horizon,\n            gap=gap,\n            stride=stride,\n            window=window,\n            mode=mode,\n        )\n\n        self.time_series_ = time_series\n        self.start_dt_ = start_dt\n        self.end_dt_ = end_dt\n\n        self.n_splits = self._compute_n_splits()\n        self.size_ = time_series.shape[0]\n\n    def split(\n        self: Self,\n        X: NDArray | None = None,\n        y: NDArray | None = None,\n        groups: NDArray | None = None,\n    ) -&gt; Generator[tuple[NDArray[np.int_], NDArray[np.int_]], None, None]:\n        \"\"\"Generates integer indices corresponding to train and test sets.\n\n        Arguments:\n            X: Optional input features array.\n            y: Optional target variable array.\n            groups: Optional array containing group labels for the samples.\n\n        Returns:\n            A generator that yields tuples of train and test indices.\n\n        Raises:\n            ValueError: If the input arrays have incompatible lengths with reference `time_series`.\n\n        \"\"\"\n        self._validate_split_args(self.size_, X, y, groups)\n\n        _indexes = np.arange(self.size_)\n\n        yield from self.splitter.split(  # type: ignore[call-overload]\n            _indexes,\n            time_series=self.time_series_,\n            start_dt=self.start_dt_,\n            end_dt=self.end_dt_,\n            return_splitstate=False,\n        )\n\n    def get_n_splits(\n        self: Self,\n        X: NDArray | None = None,\n        y: NDArray | None = None,\n        groups: NDArray | None = None,\n    ) -&gt; int:\n        \"\"\"Returns the number of splits that can be generated from the instance.\n\n        Arguments:\n            X: Unused, exists for compatibility, checked if not None.\n            y: Unused, exists for compatibility, checked if not None.\n            groups: Unused, exists for compatibility, checked if not None.\n\n        Returns:\n            The number of splits that can be generated from `time_series`.\n        \"\"\"\n        self._validate_split_args(self.size_, X, y, groups)\n        return self.n_splits\n\n    def _compute_n_splits(self: Self) -&gt; int:\n        \"\"\"Computes number of splits just once in the init.\"\"\"\n        time_start = self.start_dt_ or self.time_series_.min()\n        time_end = self.end_dt_ or self.time_series_.max()\n\n        return len(tuple(self.splitter._splits_from_period(time_start, time_end)))  # noqa: SLF001\n\n    @staticmethod\n    def _validate_split_args(\n        size: int,\n        X: NDArray | None = None,\n        y: NDArray | None = None,\n        groups: NDArray | None = None,\n    ) -&gt; None:\n        \"\"\"Validates the arguments passed to the `split` and `get_n_splits` methods.\"\"\"\n        if X is not None and X.shape[0] != size:\n            msg = f\"Invalid shape: {X.shape[0]=} doesn't match time_series.shape[0]={size}\"\n            raise ValueError(msg)\n\n        if y is not None and y.shape[0] != size:\n            msg = f\"Invalid shape: {y.shape[0]=} doesn't match time_series.shape[0]={size}\"\n            raise ValueError(msg)\n\n        if groups is not None and groups.shape[0] != size:\n            msg = f\"Invalid shape: {groups.shape[0]=} doesn't match time_series.shape[0]={size}\"\n            raise ValueError(msg)\n</code></pre>"},{"location":"api/sklearn/#timebasedcv.sklearn.TimeBasedCVSplitter.split","title":"split","text":"<pre><code>split(X: NDArray | None = None, y: NDArray | None = None, groups: NDArray | None = None) -&gt; Generator[tuple[NDArray[int_], NDArray[int_]], None, None]\n</code></pre> <p>Generates integer indices corresponding to train and test sets.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>NDArray | None</code> <p>Optional input features array.</p> <code>None</code> <code>y</code> <code>NDArray | None</code> <p>Optional target variable array.</p> <code>None</code> <code>groups</code> <code>NDArray | None</code> <p>Optional array containing group labels for the samples.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>A generator that yields tuples of train and test indices.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input arrays have incompatible lengths with reference <code>time_series</code>.</p> Source code in <code>timebasedcv/sklearn.py</code> <pre><code>def split(\n    self: Self,\n    X: NDArray | None = None,\n    y: NDArray | None = None,\n    groups: NDArray | None = None,\n) -&gt; Generator[tuple[NDArray[np.int_], NDArray[np.int_]], None, None]:\n    \"\"\"Generates integer indices corresponding to train and test sets.\n\n    Arguments:\n        X: Optional input features array.\n        y: Optional target variable array.\n        groups: Optional array containing group labels for the samples.\n\n    Returns:\n        A generator that yields tuples of train and test indices.\n\n    Raises:\n        ValueError: If the input arrays have incompatible lengths with reference `time_series`.\n\n    \"\"\"\n    self._validate_split_args(self.size_, X, y, groups)\n\n    _indexes = np.arange(self.size_)\n\n    yield from self.splitter.split(  # type: ignore[call-overload]\n        _indexes,\n        time_series=self.time_series_,\n        start_dt=self.start_dt_,\n        end_dt=self.end_dt_,\n        return_splitstate=False,\n    )\n</code></pre>"},{"location":"api/sklearn/#timebasedcv.sklearn.TimeBasedCVSplitter.get_n_splits","title":"get_n_splits","text":"<pre><code>get_n_splits(X: NDArray | None = None, y: NDArray | None = None, groups: NDArray | None = None) -&gt; int\n</code></pre> <p>Returns the number of splits that can be generated from the instance.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>NDArray | None</code> <p>Unused, exists for compatibility, checked if not None.</p> <code>None</code> <code>y</code> <code>NDArray | None</code> <p>Unused, exists for compatibility, checked if not None.</p> <code>None</code> <code>groups</code> <code>NDArray | None</code> <p>Unused, exists for compatibility, checked if not None.</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>The number of splits that can be generated from <code>time_series</code>.</p> Source code in <code>timebasedcv/sklearn.py</code> <pre><code>def get_n_splits(\n    self: Self,\n    X: NDArray | None = None,\n    y: NDArray | None = None,\n    groups: NDArray | None = None,\n) -&gt; int:\n    \"\"\"Returns the number of splits that can be generated from the instance.\n\n    Arguments:\n        X: Unused, exists for compatibility, checked if not None.\n        y: Unused, exists for compatibility, checked if not None.\n        groups: Unused, exists for compatibility, checked if not None.\n\n    Returns:\n        The number of splits that can be generated from `time_series`.\n    \"\"\"\n    self._validate_split_args(self.size_, X, y, groups)\n    return self.n_splits\n</code></pre>"},{"location":"api/splitstate/","title":"<code>timebasedcv.splitstate</code>","text":""},{"location":"api/splitstate/#timebasedcv.splitstate.SplitState","title":"timebasedcv.splitstate.SplitState  <code>dataclass</code>","text":"<p>               Bases: <code>Generic[DateTimeLike]</code></p> <p>A <code>SplitState</code> represents the state of a split in terms of its four cut/split points.</p> <p>Namely these are start and end of training set, start and end of forecasting/test set.</p> <p>The class ensures that the split is valid by checking that the attributes are of the correct type and are ordered chronologically.</p> <p>The class provides properties to calculate the length of the training set, forecast set, gap between them, and the total length of the split.</p> <p>Parameters:</p> Name Type Description Default <code>train_start</code> <code>DateTimeLike</code> <p>The start of the training set.</p> required <code>train_end</code> <code>DateTimeLike</code> <p>The end of the training set.</p> required <code>forecast_start</code> <code>DateTimeLike</code> <p>The start of the forecast set.</p> required <code>forecast_end</code> <code>DateTimeLike</code> <p>The end of the forecast set.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If any of the attributes is not of type <code>datetime</code>, <code>date</code> or <code>pd.Timestamp</code>.</p> <code>ValueError</code> <p>If the attributes are not ordered chronologically.</p> Source code in <code>timebasedcv/splitstate.py</code> <pre><code>@dataclass(frozen=True)\nclass SplitState(Generic[DateTimeLike]):\n    \"\"\"A `SplitState` represents the state of a split in terms of its four cut/split points.\n\n    Namely these are start and end of training set, start and end of forecasting/test set.\n\n    The class ensures that the split is valid by checking that the attributes are of the correct type and are ordered\n    chronologically.\n\n    The class provides properties to calculate the length of the training set, forecast set, gap between them, and the\n    total length of the split.\n\n    Arguments:\n        train_start: The start of the training set.\n        train_end: The end of the training set.\n        forecast_start: The start of the forecast set.\n        forecast_end: The end of the forecast set.\n\n    Raises:\n        TypeError: If any of the attributes is not of type `datetime`, `date` or `pd.Timestamp`.\n        ValueError: If the attributes are not ordered chronologically.\n    \"\"\"\n\n    __slots__ = (  # noqa: RUF023\n        \"train_start\",\n        \"train_end\",\n        \"forecast_start\",\n        \"forecast_end\",\n    )\n\n    train_start: DateTimeLike\n    train_end: DateTimeLike\n    forecast_start: DateTimeLike\n    forecast_end: DateTimeLike\n\n    def __post_init__(self: Self) -&gt; None:\n        \"\"\"Post init used to validate the `SplitState` instance attributes.\"\"\"\n        # Validate types\n        _slots = self.__slots__\n        _values = tuple(getattr(self, _attr) for _attr in _slots)\n        _types = tuple(type(_value) for _value in _values)\n\n        pd = get_pandas()\n\n        if not (\n            all(_type is datetime for _type in _types)\n            or all(_type is date for _type in _types)\n            or (pd is not None and all(_type is pd.Timestamp for _type in _types))\n        ):\n            # cfr: https://stackoverflow.com/questions/16991948/detect-if-a-variable-is-a-datetime-object\n            msg = \"All attributes must be of type `datetime`, `date` or `pd.Timestamp`.\"\n            raise TypeError(msg)\n\n        # Validate order\n        _ordered = tuple(pairwise_comparison(_values, less_or_equal))\n\n        if not all(_ordered):\n            _error_msg = \"\\n\".join(\n                f\"{s1}({v1}) is greater or equal to {s2}({v2})\"\n                for (s1, s2), (v1, v2), is_ordered in zip(pairwise(_slots), pairwise(_values), _ordered)\n                if not is_ordered\n            )\n            msg = f\"`{'`, `'.join(_slots)}` must be ordered. Found:\\n{_error_msg}\"\n            raise ValueError(msg)\n\n    @property\n    def train_length(self: Self) -&gt; relativedelta:\n        \"\"\"Returns the time between `train_start` and `train_end`.\n\n        Returns:\n            A `relativedelta` object representing the time between `train_start` and `train_end`.\n        \"\"\"\n        return relativedelta(self.train_end, self.train_start)\n\n    @property\n    def forecast_length(self: Self) -&gt; relativedelta:\n        \"\"\"Returns the time between `forecast_start` and `forecast_end`.\n\n        Returns:\n            A `relativedelta` object representing the time between `forecast_start` and `forecast_end`.\n        \"\"\"\n        return relativedelta(self.forecast_end, self.forecast_start)\n\n    @property\n    def gap_length(self: Self) -&gt; relativedelta:\n        \"\"\"Returns the time between `train_end` and `forecast_start`.\n\n        Returns:\n            A `relativedelta` object representing the time between `train_end` and `forecast_start`.\n        \"\"\"\n        return relativedelta(self.forecast_start, self.train_end)\n\n    @property\n    def total_length(self: Self) -&gt; relativedelta:\n        \"\"\"Returns the time between `train_start` and `forecast_end`.\n\n        Returns:\n            A `relativedelta` object representing the time between `train_start` and `forecast_end`.\n        \"\"\"\n        return relativedelta(self.forecast_end, self.train_start)\n\n    def __add__(self: Self, other: timedelta | relativedelta | pd.Timedelta) -&gt; SplitState:\n        \"\"\"Adds `other` to each value of the state.\"\"\"\n        return SplitState(\n            train_start=self.train_start + other,\n            train_end=self.train_end + other,\n            forecast_start=self.forecast_start + other,\n            forecast_end=self.forecast_end + other,\n        )\n\n    def __sub__(self: Self, other: timedelta | relativedelta | pd.Timedelta) -&gt; SplitState:\n        \"\"\"Subtracts other to each value of the state.\"\"\"\n        return SplitState(\n            train_start=self.train_start - other,\n            train_end=self.train_end - other,\n            forecast_start=self.forecast_start - other,\n            forecast_end=self.forecast_end - other,\n        )\n</code></pre>"},{"location":"api/splitstate/#timebasedcv.splitstate.SplitState.forecast_length","title":"forecast_length  <code>property</code>","text":"<pre><code>forecast_length: relativedelta\n</code></pre> <p>Returns the time between <code>forecast_start</code> and <code>forecast_end</code>.</p> <p>Returns:</p> Type Description <code>relativedelta</code> <p>A <code>relativedelta</code> object representing the time between <code>forecast_start</code> and <code>forecast_end</code>.</p>"},{"location":"api/splitstate/#timebasedcv.splitstate.SplitState.gap_length","title":"gap_length  <code>property</code>","text":"<pre><code>gap_length: relativedelta\n</code></pre> <p>Returns the time between <code>train_end</code> and <code>forecast_start</code>.</p> <p>Returns:</p> Type Description <code>relativedelta</code> <p>A <code>relativedelta</code> object representing the time between <code>train_end</code> and <code>forecast_start</code>.</p>"},{"location":"api/splitstate/#timebasedcv.splitstate.SplitState.total_length","title":"total_length  <code>property</code>","text":"<pre><code>total_length: relativedelta\n</code></pre> <p>Returns the time between <code>train_start</code> and <code>forecast_end</code>.</p> <p>Returns:</p> Type Description <code>relativedelta</code> <p>A <code>relativedelta</code> object representing the time between <code>train_start</code> and <code>forecast_end</code>.</p>"},{"location":"api/splitstate/#timebasedcv.splitstate.SplitState.train_length","title":"train_length  <code>property</code>","text":"<pre><code>train_length: relativedelta\n</code></pre> <p>Returns the time between <code>train_start</code> and <code>train_end</code>.</p> <p>Returns:</p> Type Description <code>relativedelta</code> <p>A <code>relativedelta</code> object representing the time between <code>train_start</code> and <code>train_end</code>.</p>"},{"location":"api/splitstate/#timebasedcv.splitstate.SplitState.__add__","title":"__add__","text":"<pre><code>__add__(other: timedelta | relativedelta | Timedelta) -&gt; SplitState\n</code></pre> <p>Adds <code>other</code> to each value of the state.</p> Source code in <code>timebasedcv/splitstate.py</code> <pre><code>def __add__(self: Self, other: timedelta | relativedelta | pd.Timedelta) -&gt; SplitState:\n    \"\"\"Adds `other` to each value of the state.\"\"\"\n    return SplitState(\n        train_start=self.train_start + other,\n        train_end=self.train_end + other,\n        forecast_start=self.forecast_start + other,\n        forecast_end=self.forecast_end + other,\n    )\n</code></pre>"},{"location":"api/splitstate/#timebasedcv.splitstate.SplitState.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__() -&gt; None\n</code></pre> <p>Post init used to validate the <code>SplitState</code> instance attributes.</p> Source code in <code>timebasedcv/splitstate.py</code> <pre><code>def __post_init__(self: Self) -&gt; None:\n    \"\"\"Post init used to validate the `SplitState` instance attributes.\"\"\"\n    # Validate types\n    _slots = self.__slots__\n    _values = tuple(getattr(self, _attr) for _attr in _slots)\n    _types = tuple(type(_value) for _value in _values)\n\n    pd = get_pandas()\n\n    if not (\n        all(_type is datetime for _type in _types)\n        or all(_type is date for _type in _types)\n        or (pd is not None and all(_type is pd.Timestamp for _type in _types))\n    ):\n        # cfr: https://stackoverflow.com/questions/16991948/detect-if-a-variable-is-a-datetime-object\n        msg = \"All attributes must be of type `datetime`, `date` or `pd.Timestamp`.\"\n        raise TypeError(msg)\n\n    # Validate order\n    _ordered = tuple(pairwise_comparison(_values, less_or_equal))\n\n    if not all(_ordered):\n        _error_msg = \"\\n\".join(\n            f\"{s1}({v1}) is greater or equal to {s2}({v2})\"\n            for (s1, s2), (v1, v2), is_ordered in zip(pairwise(_slots), pairwise(_values), _ordered)\n            if not is_ordered\n        )\n        msg = f\"`{'`, `'.join(_slots)}` must be ordered. Found:\\n{_error_msg}\"\n        raise ValueError(msg)\n</code></pre>"},{"location":"api/splitstate/#timebasedcv.splitstate.SplitState.__sub__","title":"__sub__","text":"<pre><code>__sub__(other: timedelta | relativedelta | Timedelta) -&gt; SplitState\n</code></pre> <p>Subtracts other to each value of the state.</p> Source code in <code>timebasedcv/splitstate.py</code> <pre><code>def __sub__(self: Self, other: timedelta | relativedelta | pd.Timedelta) -&gt; SplitState:\n    \"\"\"Subtracts other to each value of the state.\"\"\"\n    return SplitState(\n        train_start=self.train_start - other,\n        train_end=self.train_end - other,\n        forecast_start=self.forecast_start - other,\n        forecast_end=self.forecast_end - other,\n    )\n</code></pre>"},{"location":"api/timebasedcv/","title":"<code>timebasedcv</code>","text":"<p>Here are the top-level classes available in timebasedcv.</p>"},{"location":"api/timebasedcv/#timebasedcv.core.TimeBasedSplit","title":"timebasedcv.core.TimeBasedSplit","text":"<p>               Bases: <code>_CoreTimeBasedSplit</code></p> <p><code>TimeBasedSplit</code> generates splits based on time periods, independently from the number of samples in each split.</p> <p>It inherits from <code>_CoreTimeBasedSplit</code> and it only implements the <code>.split()</code> method and logic.</p> <p>Differences with scikit-learn</p> <p><code>TimeBasedSplit</code> is not compatible with scikit-learn CV Splitters.</p> <p>In fact, we have made the (opinioned) choice to:</p> <ul> <li>Return the sliced arrays from <code>.split(...)</code>, while scikit-learn CV Splitters return train and test indices of     the split.</li> <li>Require to pass the time series as input to <code>.split(...)</code> method, while scikit-learn CV Splitters require to     provide only <code>X, y, groups</code> to <code>.split(...)</code>.</li> <li>Such time series is used to generate the boolean masks with which we slice the original arrays into train and     test for each split.</li> </ul> <p>If you are looking for a class compatible with scikit-learn, check out our <code>TimeBasedCVSplitter</code> in the <code>timebasedcv.sklearn</code> module.</p> <p>A few examples on how splits are generated given the parameters. Let:</p> <ul> <li><code>=</code> : train period unit</li> <li><code>*</code> : forecast period unit</li> <li><code>/</code> : gap period unit</li> <li><code>&gt;</code> : stride period unit (absorbed in <code>=</code> if <code>window=\"expanding\"</code>)</li> </ul> <p>Recall also that if <code>stride</code> is not provided, it is set to <code>forecast_horizon</code>: <pre><code>train_size, forecast_horizon, gap, stride, window = (4, 3, 0, None, \"rolling\")\n| ======= *****               |\n| &gt;&gt;&gt;&gt;&gt; ======= *****         |\n|       &gt;&gt;&gt;&gt;&gt; ======= *****   |\n|             &gt;&gt;&gt;&gt;&gt; ======= * |\n\ntrain_size, forecast_horizon, gap, stride, window = (4, 3, 2, 2, \"rolling\")\n\n| ======= /// *****           |\n| &gt;&gt;&gt; ======= /// *****       |\n|     &gt;&gt;&gt; ======= /// *****   |\n|         &gt;&gt;&gt; ======= /// *** |\n\ntrain_size, forecast_horizon, gap, stride, window = (4, 3, 2, 2, \"expanding\")\n| ======= /// *****           |\n| =========== /// *****       |\n| =============== /// *****   |\n| =================== /// *** |\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>frequency</code> <code>FrequencyUnit</code> <p>The frequency (or time unit) of the time series. Must be one of \"days\", \"seconds\", \"microseconds\", \"milliseconds\", \"minutes\", \"hours\", \"weeks\", \"months\" or \"years\". These are the valid values for the <code>unit</code> argument of <code>relativedelta</code> from python <code>dateutil</code> library.</p> required <code>train_size</code> <code>int</code> <p>Defines the minimum number of time units required to be in the train set.</p> required <code>forecast_horizon</code> <code>int</code> <p>Specifies the number of time units to forecast.</p> required <code>gap</code> <code>int</code> <p>Sets the number of time units to skip between the end of the train set and the start of the forecast set.</p> <code>0</code> <code>stride</code> <code>int | None</code> <p>How many time unit to move forward after each split. If <code>None</code> (or set to 0), the stride is equal to the <code>forecast_horizon</code> quantity.</p> <code>None</code> <code>window</code> <code>WindowType</code> <p>The type of window to use, either \"rolling\" or \"expanding\".</p> <code>'rolling'</code> <code>mode</code> <code>ModeType</code> <p>Determines in which orders the splits are generated, either \"forward\" (start to end) or \"backward\" (end to start).</p> <code>'forward'</code> <p>Raises:</p> Type Description <code>ValueError</code> <ul> <li>If <code>frequency</code> is not one of \"days\", \"seconds\", \"microseconds\", \"milliseconds\", \"minutes\", \"hours\", \"weeks\".</li> <li>If <code>window</code> is not one of \"rolling\" or \"expanding\".</li> <li>If <code>mode</code> is not one of \"forward\" or \"backward\"</li> <li>If <code>train_size</code>, <code>forecast_horizon</code>, <code>gap</code> or <code>stride</code> are not strictly positive.</li> </ul> <code>TypeError</code> <p>If <code>train_size</code>, <code>forecast_horizon</code>, <code>gap</code> or <code>stride</code> are not of type <code>int</code>.</p> <p>Examples:</p> <pre><code># Let's first generate some data\nimport pandas as pd\nimport numpy as np\n\nRNG = np.random.default_rng(seed=42)\n\ndates = pd.Series(pd.date_range(\"2023-01-01\", \"2023-01-31\", freq=\"D\"))\nsize = len(dates)\n\ndf = (\n    pd.concat(\n        [\n            pd.DataFrame(\n                {\n                    \"time\": pd.date_range(start, end, periods=_size, inclusive=\"left\"),\n                    \"a\": RNG.normal(size=_size - 1),\n                    \"b\": RNG.normal(size=_size - 1),\n                }\n            )\n            for start, end, _size in zip(dates[:-1], dates[1:], RNG.integers(2, 24, size - 1))\n        ]\n    )\n    .reset_index(drop=True)\n    .assign(y=lambda t: t[[\"a\", \"b\"]].sum(axis=1) + RNG.normal(size=t.shape[0]) / 25)\n)\n\ndf.set_index(\"time\").resample(\"D\").agg(count=(\"y\", np.size)).head(5)\n</code></pre> <pre><code>            count\ntime\n2023-01-01      2\n2023-01-02     18\n2023-01-03     15\n2023-01-04     10\n2023-01-05     10\n</code></pre> <p>Now let's run split the data with the provided <code>TimeBasedSplit</code> instance:</p> <pre><code>from timebasedcv import TimeBasedSplit\n\n\ntbs = TimeBasedSplit(\n    frequency=\"days\",\n    train_size=10,\n    forecast_horizon=5,\n    gap=1,\n    stride=3\n)\nX, y, time_series = df.loc[:, [\"a\", \"b\"]], df[\"y\"], df[\"time\"]\n\nfor X_train, X_forecast, y_train, y_forecast in tbs.split(X, y, time_series=time_series):\n    print(f\"Train: {X_train.shape}, Forecast: {X_forecast.shape}\")\n</code></pre> <pre><code>Train: (100, 2), Forecast: (51, 2)\nTrain: (114, 2), Forecast: (50, 2)\n...\nTrain: (124, 2), Forecast: (40, 2)\nTrain: (137, 2), Forecast: (22, 2)\n</code></pre> Source code in <code>timebasedcv/core.py</code> <pre><code>class TimeBasedSplit(_CoreTimeBasedSplit):\n    \"\"\"`TimeBasedSplit` generates splits based on time periods, independently from the number of samples in each split.\n\n    It inherits from [`_CoreTimeBasedSplit`][timebasedcv.core._CoreTimeBasedSplit] and it only implements the `.split()`\n    method and logic.\n\n    !!! warning \"Differences with scikit-learn\"\n\n        `TimeBasedSplit` is **not** compatible with\n        [scikit-learn CV Splitters](https://scikit-learn.org/stable/common_pitfalls.html#id3){:target=\"_blank\"}.\n\n        In fact, we have made the (opinioned) choice to:\n\n        - Return the sliced arrays from `.split(...)`, while scikit-learn CV Splitters return train and test indices of\n            the split.\n        - Require to pass the time series as input to `.split(...)` method, while scikit-learn CV Splitters require to\n            provide only `X, y, groups` to `.split(...)`.\n        - Such time series is used to generate the boolean masks with which we slice the original arrays into train and\n            test for each split.\n\n        If you are looking for a class compatible with scikit-learn, check out our\n        [`TimeBasedCVSplitter`][timebasedcv.sklearn.TimeBasedCVSplitter] in the `timebasedcv.sklearn` module.\n\n    A few examples on how splits are generated given the parameters. Let:\n\n    - `=` : train period unit\n    - `*` : forecast period unit\n    - `/` : gap period unit\n    - `&gt;` : stride period unit (absorbed in `=` if `window=\"expanding\"`)\n\n    Recall also that if `stride` is not provided, it is set to `forecast_horizon`:\n    ```\n    train_size, forecast_horizon, gap, stride, window = (4, 3, 0, None, \"rolling\")\n    | ======= *****               |\n    | &gt;&gt;&gt;&gt;&gt; ======= *****         |\n    |       &gt;&gt;&gt;&gt;&gt; ======= *****   |\n    |             &gt;&gt;&gt;&gt;&gt; ======= * |\n\n    train_size, forecast_horizon, gap, stride, window = (4, 3, 2, 2, \"rolling\")\n\n    | ======= /// *****           |\n    | &gt;&gt;&gt; ======= /// *****       |\n    |     &gt;&gt;&gt; ======= /// *****   |\n    |         &gt;&gt;&gt; ======= /// *** |\n\n    train_size, forecast_horizon, gap, stride, window = (4, 3, 2, 2, \"expanding\")\n    | ======= /// *****           |\n    | =========== /// *****       |\n    | =============== /// *****   |\n    | =================== /// *** |\n    ```\n\n    Arguments:\n        frequency: The frequency (or time unit) of the time series. Must be one of \"days\", \"seconds\", \"microseconds\",\n            \"milliseconds\", \"minutes\", \"hours\", \"weeks\", \"months\" or \"years\". These are the valid values for the\n            `unit` argument of `relativedelta` from python `dateutil` library.\n        train_size: Defines the minimum number of time units required to be in the train set.\n        forecast_horizon: Specifies the number of time units to forecast.\n        gap: Sets the number of time units to skip between the end of the train set and the start of the forecast set.\n        stride: How many time unit to move forward after each split. If `None` (or set to 0), the stride is equal to the\n            `forecast_horizon` quantity.\n        window: The type of window to use, either \"rolling\" or \"expanding\".\n        mode: Determines in which orders the splits are generated, either \"forward\" (start to end) or \"backward\"\n            (end to start).\n\n    Raises:\n        ValueError:\n            - If `frequency` is not one of \"days\", \"seconds\", \"microseconds\", \"milliseconds\", \"minutes\", \"hours\",\n            \"weeks\".\n            - If `window` is not one of \"rolling\" or \"expanding\".\n            - If `mode` is not one of \"forward\" or \"backward\"\n            - If `train_size`, `forecast_horizon`, `gap` or `stride` are not strictly positive.\n        TypeError: If `train_size`, `forecast_horizon`, `gap` or `stride` are not of type `int`.\n\n\n    Examples:\n        ```python\n        # Let's first generate some data\n        import pandas as pd\n        import numpy as np\n\n        RNG = np.random.default_rng(seed=42)\n\n        dates = pd.Series(pd.date_range(\"2023-01-01\", \"2023-01-31\", freq=\"D\"))\n        size = len(dates)\n\n        df = (\n            pd.concat(\n                [\n                    pd.DataFrame(\n                        {\n                            \"time\": pd.date_range(start, end, periods=_size, inclusive=\"left\"),\n                            \"a\": RNG.normal(size=_size - 1),\n                            \"b\": RNG.normal(size=_size - 1),\n                        }\n                    )\n                    for start, end, _size in zip(dates[:-1], dates[1:], RNG.integers(2, 24, size - 1))\n                ]\n            )\n            .reset_index(drop=True)\n            .assign(y=lambda t: t[[\"a\", \"b\"]].sum(axis=1) + RNG.normal(size=t.shape[0]) / 25)\n        )\n\n        df.set_index(\"time\").resample(\"D\").agg(count=(\"y\", np.size)).head(5)\n        ```\n\n        ```terminal\n                    count\n        time\n        2023-01-01      2\n        2023-01-02     18\n        2023-01-03     15\n        2023-01-04     10\n        2023-01-05     10\n        ```\n\n        Now let's run split the data with the provided `TimeBasedSplit` instance:\n\n        ```py\n        from timebasedcv import TimeBasedSplit\n\n\n        tbs = TimeBasedSplit(\n            frequency=\"days\",\n            train_size=10,\n            forecast_horizon=5,\n            gap=1,\n            stride=3\n        )\n        X, y, time_series = df.loc[:, [\"a\", \"b\"]], df[\"y\"], df[\"time\"]\n\n        for X_train, X_forecast, y_train, y_forecast in tbs.split(X, y, time_series=time_series):\n            print(f\"Train: {X_train.shape}, Forecast: {X_forecast.shape}\")\n        ```\n\n        ```terminal\n        Train: (100, 2), Forecast: (51, 2)\n        Train: (114, 2), Forecast: (50, 2)\n        ...\n        Train: (124, 2), Forecast: (40, 2)\n        Train: (137, 2), Forecast: (22, 2)\n        ```\n    \"\"\"\n\n    @overload\n    def split(\n        self: Self,\n        *arrays: TensorLikeT,\n        time_series: SeriesLike[DateTimeLike],\n        start_dt: NullableDatetime = None,\n        end_dt: NullableDatetime = None,\n        return_splitstate: Literal[False],\n    ) -&gt; Generator[tuple[TensorLikeT, ...], None, None]: ...  # pragma: no cover\n\n    @overload\n    def split(\n        self: Self,\n        *arrays: TensorLikeT,\n        time_series: SeriesLike[DateTimeLike],\n        start_dt: NullableDatetime = None,\n        end_dt: NullableDatetime = None,\n        return_splitstate: Literal[True],\n    ) -&gt; Generator[tuple[tuple[TensorLikeT, ...], SplitState], None, None]: ...  # pragma: no cover\n\n    @overload\n    def split(\n        self: Self,\n        *arrays: TensorLikeT,\n        time_series: SeriesLike[DateTimeLike],\n        start_dt: NullableDatetime = None,\n        end_dt: NullableDatetime = None,\n        return_splitstate: bool = False,\n    ) -&gt; Generator[\n        tuple[TensorLikeT, ...] | tuple[tuple[TensorLikeT, ...], SplitState],\n        None,\n        None,\n    ]: ...  # pragma: no cover\n\n    def split(\n        self: Self,\n        *arrays: TensorLikeT,\n        time_series: SeriesLike[DateTimeLike],\n        start_dt: NullableDatetime = None,\n        end_dt: NullableDatetime = None,\n        return_splitstate: bool = False,\n    ) -&gt; Generator[tuple[TensorLikeT, ...] | tuple[tuple[TensorLikeT, ...], SplitState], None, None]:\n        \"\"\"Returns a generator of split arrays based on the `time_series`.\n\n        The `time_series` argument is split on split state values to create boolean masks for training - from train_\n        start (included) to train_end (excluded) - and forecast - from forecast_start (included) to forecast_end\n        (excluded). These masks are then used to index the arrays passed as arguments.\n\n        The `start_dt` and `end_dt` arguments can be used to specify the start and end of the time period. If provided,\n        they are used in place of the `time_series.min()` and `time_series.max()` respectively.\n\n        This is useful because the series does not necessarely starts from the first date and/or terminates in the last\n        date of the time period of interest.\n\n        The `return_splitstate` argument can be used to return the `SplitState` instance for each split. This can be\n        useful if a particular logic has to be applied only on specific cases (e.g. if first day of the week, then\n        retrain a model).\n\n        By returning the split state, the user has the freedom and flexibility to apply any logic.\n\n        Arguments:\n            *arrays: The arrays to split. Must have the same length as `time_series`.\n            time_series: The time series used to create boolean mask for splits. It is not required to be sorted, but it\n                must support:\n\n                - comparison operators (with other date-like objects).\n                - bitwise operators (with other boolean arrays).\n                - `.min()` and `.max()` methods.\n                - `.shape` attribute.\n            start_dt: The start of the time period. If provided, it is used in place of the `time_series.min()`.\n            end_dt: The end of the time period. If provided,it is used in place of the `time_series.max()`.\n            return_splitstate: Whether to return the `SplitState` instance for each split.\n\n                - If True, the generator yields tuples of the form `(train_forecast_arrays, split_state)`, where\n                `train_forecast_arrays` is a tuple of arrays containing the training and forecast data, and\n                `split_state` is a `SplitState` instance representing the current split.\n                - If False, the generator yields tuples of the form `train_forecast_arrays`.\n\n        Returns:\n            A generator of tuples of arrays containing the training and forecast data.\n                Each tuple corresponds to a split generated by the `TimeBasedSplit` instance. If `return_splitstate` is\n                True, each tuple is of the form `(train_forecast_arrays, split_state)`, othersiwe it is of the form\n                `train_forecast_arrays`.\n\n        Raises:\n            ValueError:\n                - If no arrays are provided as input.\n                - If the arrays provided have different lengths.\n                - If the length of the time series does not match the length of the arrays.\n        \"\"\"\n        n_arrays = len(arrays)\n        if n_arrays == 0:\n            msg = \"At least one array required as input\"\n            raise ValueError(msg)\n\n        arrays_: tuple[nw.DataFrame | nw.Series | np.ndarray, ...] = tuple(\n            nw.from_native(array, eager_only=True, allow_series=True, strict=False) for array in arrays\n        )\n        time_series_: nw.Series | np.ndarray = nw.from_native(time_series, series_only=True, strict=False)\n\n        ts_shape = time_series_.shape\n        if len(ts_shape) != 1:\n            msg = f\"Time series must be 1-dimensional. Got {len(ts_shape)} dimensions.\"\n            raise ValueError(msg)\n\n        a0 = arrays[0]\n        arr_len = a0.shape[0]\n\n        if n_arrays &gt; 1 and not all(a.shape[0] == arr_len for a in arrays_[1:]):\n            msg = f\"All arrays must have the same length. Got {[a.shape[0] for a in arrays_]}\"\n            raise ValueError(msg)\n\n        if arr_len != ts_shape[0]:\n            msg = f\"Time series and arrays must have the same length. Got {arr_len} and {ts_shape[0]}\"\n            raise ValueError(msg)\n\n        time_start, time_end = start_dt or time_series_.min(), end_dt or time_series_.max()\n\n        if time_start &gt;= time_end:\n            msg = \"`time_start` must be before `time_end`.\"\n            raise ValueError(msg)\n\n        _index_methods = tuple(BACKEND_TO_INDEXING_METHOD.get(str(type(a)), default_indexing_method) for a in arrays_)\n        for split in self._splits_from_period(time_start, time_end):\n            train_mask = (time_series_ &gt;= split.train_start) &amp; (time_series_ &lt; split.train_end)\n            forecast_mask = (time_series_ &gt;= split.forecast_start) &amp; (time_series_ &lt; split.forecast_end)\n\n            train_forecast_arrays = tuple(\n                chain.from_iterable(\n                    (\n                        nw.to_native(_idx_method(_arr, train_mask), strict=False),\n                        nw.to_native(_idx_method(_arr, forecast_mask), strict=False),\n                    )\n                    for _arr, _idx_method in zip(arrays_, _index_methods)\n                ),\n            )\n\n            if return_splitstate:\n                yield train_forecast_arrays, split\n            else:\n                yield train_forecast_arrays\n</code></pre>"},{"location":"api/timebasedcv/#timebasedcv.core.TimeBasedSplit.split","title":"split","text":"<pre><code>split(*arrays: TensorLikeT, time_series: SeriesLike[DateTimeLike], start_dt: NullableDatetime = None, end_dt: NullableDatetime = None, return_splitstate: bool = False) -&gt; Generator[tuple[TensorLikeT, ...] | tuple[tuple[TensorLikeT, ...], SplitState], None, None]\n</code></pre> <p>Returns a generator of split arrays based on the <code>time_series</code>.</p> <p>The <code>time_series</code> argument is split on split state values to create boolean masks for training - from train_ start (included) to train_end (excluded) - and forecast - from forecast_start (included) to forecast_end (excluded). These masks are then used to index the arrays passed as arguments.</p> <p>The <code>start_dt</code> and <code>end_dt</code> arguments can be used to specify the start and end of the time period. If provided, they are used in place of the <code>time_series.min()</code> and <code>time_series.max()</code> respectively.</p> <p>This is useful because the series does not necessarely starts from the first date and/or terminates in the last date of the time period of interest.</p> <p>The <code>return_splitstate</code> argument can be used to return the <code>SplitState</code> instance for each split. This can be useful if a particular logic has to be applied only on specific cases (e.g. if first day of the week, then retrain a model).</p> <p>By returning the split state, the user has the freedom and flexibility to apply any logic.</p> <p>Parameters:</p> Name Type Description Default <code>*arrays</code> <code>TensorLikeT</code> <p>The arrays to split. Must have the same length as <code>time_series</code>.</p> <code>()</code> <code>time_series</code> <code>SeriesLike[DateTimeLike]</code> <p>The time series used to create boolean mask for splits. It is not required to be sorted, but it must support:</p> <ul> <li>comparison operators (with other date-like objects).</li> <li>bitwise operators (with other boolean arrays).</li> <li><code>.min()</code> and <code>.max()</code> methods.</li> <li><code>.shape</code> attribute.</li> </ul> required <code>start_dt</code> <code>NullableDatetime</code> <p>The start of the time period. If provided, it is used in place of the <code>time_series.min()</code>.</p> <code>None</code> <code>end_dt</code> <code>NullableDatetime</code> <p>The end of the time period. If provided,it is used in place of the <code>time_series.max()</code>.</p> <code>None</code> <code>return_splitstate</code> <code>bool</code> <p>Whether to return the <code>SplitState</code> instance for each split.</p> <ul> <li>If True, the generator yields tuples of the form <code>(train_forecast_arrays, split_state)</code>, where <code>train_forecast_arrays</code> is a tuple of arrays containing the training and forecast data, and <code>split_state</code> is a <code>SplitState</code> instance representing the current split.</li> <li>If False, the generator yields tuples of the form <code>train_forecast_arrays</code>.</li> </ul> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>A generator of tuples of arrays containing the training and forecast data. Each tuple corresponds to a split generated by the <code>TimeBasedSplit</code> instance. If <code>return_splitstate</code> is True, each tuple is of the form <code>(train_forecast_arrays, split_state)</code>, othersiwe it is of the form <code>train_forecast_arrays</code>.</p> <p>Raises:</p> Type Description <code>ValueError</code> <ul> <li>If no arrays are provided as input.</li> <li>If the arrays provided have different lengths.</li> <li>If the length of the time series does not match the length of the arrays.</li> </ul> Source code in <code>timebasedcv/core.py</code> <pre><code>def split(\n    self: Self,\n    *arrays: TensorLikeT,\n    time_series: SeriesLike[DateTimeLike],\n    start_dt: NullableDatetime = None,\n    end_dt: NullableDatetime = None,\n    return_splitstate: bool = False,\n) -&gt; Generator[tuple[TensorLikeT, ...] | tuple[tuple[TensorLikeT, ...], SplitState], None, None]:\n    \"\"\"Returns a generator of split arrays based on the `time_series`.\n\n    The `time_series` argument is split on split state values to create boolean masks for training - from train_\n    start (included) to train_end (excluded) - and forecast - from forecast_start (included) to forecast_end\n    (excluded). These masks are then used to index the arrays passed as arguments.\n\n    The `start_dt` and `end_dt` arguments can be used to specify the start and end of the time period. If provided,\n    they are used in place of the `time_series.min()` and `time_series.max()` respectively.\n\n    This is useful because the series does not necessarely starts from the first date and/or terminates in the last\n    date of the time period of interest.\n\n    The `return_splitstate` argument can be used to return the `SplitState` instance for each split. This can be\n    useful if a particular logic has to be applied only on specific cases (e.g. if first day of the week, then\n    retrain a model).\n\n    By returning the split state, the user has the freedom and flexibility to apply any logic.\n\n    Arguments:\n        *arrays: The arrays to split. Must have the same length as `time_series`.\n        time_series: The time series used to create boolean mask for splits. It is not required to be sorted, but it\n            must support:\n\n            - comparison operators (with other date-like objects).\n            - bitwise operators (with other boolean arrays).\n            - `.min()` and `.max()` methods.\n            - `.shape` attribute.\n        start_dt: The start of the time period. If provided, it is used in place of the `time_series.min()`.\n        end_dt: The end of the time period. If provided,it is used in place of the `time_series.max()`.\n        return_splitstate: Whether to return the `SplitState` instance for each split.\n\n            - If True, the generator yields tuples of the form `(train_forecast_arrays, split_state)`, where\n            `train_forecast_arrays` is a tuple of arrays containing the training and forecast data, and\n            `split_state` is a `SplitState` instance representing the current split.\n            - If False, the generator yields tuples of the form `train_forecast_arrays`.\n\n    Returns:\n        A generator of tuples of arrays containing the training and forecast data.\n            Each tuple corresponds to a split generated by the `TimeBasedSplit` instance. If `return_splitstate` is\n            True, each tuple is of the form `(train_forecast_arrays, split_state)`, othersiwe it is of the form\n            `train_forecast_arrays`.\n\n    Raises:\n        ValueError:\n            - If no arrays are provided as input.\n            - If the arrays provided have different lengths.\n            - If the length of the time series does not match the length of the arrays.\n    \"\"\"\n    n_arrays = len(arrays)\n    if n_arrays == 0:\n        msg = \"At least one array required as input\"\n        raise ValueError(msg)\n\n    arrays_: tuple[nw.DataFrame | nw.Series | np.ndarray, ...] = tuple(\n        nw.from_native(array, eager_only=True, allow_series=True, strict=False) for array in arrays\n    )\n    time_series_: nw.Series | np.ndarray = nw.from_native(time_series, series_only=True, strict=False)\n\n    ts_shape = time_series_.shape\n    if len(ts_shape) != 1:\n        msg = f\"Time series must be 1-dimensional. Got {len(ts_shape)} dimensions.\"\n        raise ValueError(msg)\n\n    a0 = arrays[0]\n    arr_len = a0.shape[0]\n\n    if n_arrays &gt; 1 and not all(a.shape[0] == arr_len for a in arrays_[1:]):\n        msg = f\"All arrays must have the same length. Got {[a.shape[0] for a in arrays_]}\"\n        raise ValueError(msg)\n\n    if arr_len != ts_shape[0]:\n        msg = f\"Time series and arrays must have the same length. Got {arr_len} and {ts_shape[0]}\"\n        raise ValueError(msg)\n\n    time_start, time_end = start_dt or time_series_.min(), end_dt or time_series_.max()\n\n    if time_start &gt;= time_end:\n        msg = \"`time_start` must be before `time_end`.\"\n        raise ValueError(msg)\n\n    _index_methods = tuple(BACKEND_TO_INDEXING_METHOD.get(str(type(a)), default_indexing_method) for a in arrays_)\n    for split in self._splits_from_period(time_start, time_end):\n        train_mask = (time_series_ &gt;= split.train_start) &amp; (time_series_ &lt; split.train_end)\n        forecast_mask = (time_series_ &gt;= split.forecast_start) &amp; (time_series_ &lt; split.forecast_end)\n\n        train_forecast_arrays = tuple(\n            chain.from_iterable(\n                (\n                    nw.to_native(_idx_method(_arr, train_mask), strict=False),\n                    nw.to_native(_idx_method(_arr, forecast_mask), strict=False),\n                )\n                for _arr, _idx_method in zip(arrays_, _index_methods)\n            ),\n        )\n\n        if return_splitstate:\n            yield train_forecast_arrays, split\n        else:\n            yield train_forecast_arrays\n</code></pre>"},{"location":"api/timebasedcv/#timebasedcv.core.ExpandingTimeSplit","title":"timebasedcv.core.ExpandingTimeSplit","text":"<p>               Bases: <code>TimeBasedSplit</code></p> <p>Alias for <code>TimeBasedSplit(..., window=\"expanding\")</code>.</p> Source code in <code>timebasedcv/core.py</code> <pre><code>class ExpandingTimeSplit(TimeBasedSplit):  # pragma: no cover\n    \"\"\"Alias for `TimeBasedSplit(..., window=\"expanding\")`.\"\"\"\n\n    def __init__(  # noqa: PLR0913\n        self: Self,\n        *,\n        frequency: FrequencyUnit,\n        train_size: int,\n        forecast_horizon: int,\n        gap: int = 0,\n        stride: int | None = None,\n        mode: ModeType,\n    ) -&gt; None:\n        super().__init__(\n            frequency=frequency,\n            train_size=train_size,\n            forecast_horizon=forecast_horizon,\n            gap=gap,\n            stride=stride,\n            window=\"expanding\",\n            mode=mode,\n        )\n</code></pre>"},{"location":"api/timebasedcv/#timebasedcv.core.RollingTimeSplit","title":"timebasedcv.core.RollingTimeSplit","text":"<p>               Bases: <code>TimeBasedSplit</code></p> <p>Alias for <code>TimeBasedSplit(..., window=\"rolling\")</code>.</p> Source code in <code>timebasedcv/core.py</code> <pre><code>class RollingTimeSplit(TimeBasedSplit):  # pragma: no cover\n    \"\"\"Alias for `TimeBasedSplit(..., window=\"rolling\")`.\"\"\"\n\n    def __init__(  # noqa: PLR0913\n        self: Self,\n        *,\n        frequency: FrequencyUnit,\n        train_size: int,\n        forecast_horizon: int,\n        gap: int = 0,\n        stride: int | None = None,\n        mode: ModeType,\n    ) -&gt; None:\n        super().__init__(\n            frequency=frequency,\n            train_size=train_size,\n            forecast_horizon=forecast_horizon,\n            gap=gap,\n            stride=stride,\n            window=\"rolling\",\n            mode=mode,\n        )\n</code></pre>"},{"location":"user-guide/","title":"User Guide","text":"<p>This is the user guide for the TimeBasedCV package which provides a time-based cross-validation strategy for time series data. The following sections are available:</p> <ul> <li>Getting started</li> <li>Advanced features</li> <li>Scikit-learn component</li> </ul>"},{"location":"user-guide/advanced/","title":"Advanced features \ud83d\udc0d\ud83d\udc0d","text":"<p>There are some a few more advanced features that can be used with the <code>TimeBasedSplit</code> class.</p> <p>Let's first create a dataset to show how these features work.</p> Code to generate the data Generate the data<pre><code>import numpy as np\nimport pandas as pd\n\nRNG = np.random.default_rng(seed=42)\n\ndates = pd.Series(pd.date_range(\"2023-01-01\", \"2023-01-31\", freq=\"D\"))\nsize = len(dates)\n\ndf = (pd.concat([\n        pd.DataFrame({\n            \"time\": pd.date_range(start, end, periods=_size, inclusive=\"left\"),\n            \"a\": RNG.normal(size=_size-1),\n            \"b\": RNG.normal(size=_size-1),\n        })\n        for start, end, _size in zip(dates[:-1], dates[1:], RNG.integers(2, 24, size-1))\n    ])\n    .reset_index(drop=True)\n    .assign(y=lambda t: t[[\"a\", \"b\"]].sum(axis=1) + RNG.normal(size=t.shape[0])/25)\n)\n\nX, y, time_series = df.loc[:, [\"a\", \"b\"]], df[\"y\"], df[\"time\"]\n\ndf.set_index(\"time\").resample(\"D\").agg(count=(\"y\", np.size)).head(5)\n</code></pre> <pre><code>            count\ntime\n2023-01-01      2\n2023-01-02     18\n2023-01-03     15\n2023-01-04     10\n2023-01-05     10\n</code></pre>"},{"location":"user-guide/advanced/#splitstate-information","title":"<code>SplitState</code> information","text":"<p>Internally we make use of a dataclass called <code>SplitState</code> to store the split points for training and forecasting. This dataclass can be accessed by passing the <code>return_splitstate</code> parameter to the <code>split</code> method.</p> <pre><code>from timebasedcv import TimeBasedSplit\n\ntbs = TimeBasedSplit(\n    frequency=\"days\",\n    train_size=10,\n    forecast_horizon=5,\n    gap=1,\n    stride=3,\n)\n\nfor _, split_state in tbs.split(X, y, time_series=time_series, return_splitstate=True):\n    print(split_state)\n</code></pre> <pre><code>SplitState(train_start=Timestamp('2023-01-01 00:00:00'), train_end=Timestamp('2023-01-11 00:00:00'), forecast_start=Timestamp('2023-01-12 00:00:00'), forecast_end=Timestamp('2023-01-17 00:00:00'))\nSplitState(train_start=Timestamp('2023-01-04 00:00:00'), train_end=Timestamp('2023-01-14 00:00:00'), forecast_start=Timestamp('2023-01-15 00:00:00'), forecast_end=Timestamp('2023-01-20 00:00:00'))\n...\nSplitState(train_start=Timestamp('2023-01-16 00:00:00'), train_end=Timestamp('2023-01-26 00:00:00'), forecast_start=Timestamp('2023-01-27 00:00:00'), forecast_end=Timestamp('2023-02-01 00:00:00'))\nSplitState(train_start=Timestamp('2023-01-19 00:00:00'), train_end=Timestamp('2023-01-29 00:00:00'), forecast_start=Timestamp('2023-01-30 00:00:00'), forecast_end=Timestamp('2023-02-04 00:00:00'))\n</code></pre> <p>This feature can be useful in those cases where a particular logic needs to be applied to the data before training and/or forecasting depending on the split point, or in general it yields more flexibility and control to the user.</p> <p>For instance let's say that a model is retrained only on a new week:</p> <pre><code>from sklearn import clone\nfrom sklearn.dummy import DummyRegressor\n\nmodel = DummyRegressor()\ncurrent_week = None\n\nfor (X_train, X_forecast, y_train, y_forecast), split_state in tbs.split(X, y, time_series=time_series, return_splitstate=True):\n\n    split_week = split_state.train_start.strftime(\"%Y-W%W\")\n    if  (current_week is None) or (split_week &gt; current_week):\n        model = clone(model).fit(X_train, y_train)\n        current_week = split_week\n        print(f\"\\nTraining for week {split_week}\")\n\n    score = round(model.score(X_forecast, y_forecast), 3)\n    print(f\"{score=}\")\n</code></pre> <pre><code>Training for week 2023-W00\nscore=-0.011\n\nTraining for week 2023-W01\nscore=-0.003\nscore=-0.002\n\nTraining for week 2023-W02\nscore=-0.022\nscore=-0.047\n\nTraining for week 2023-W03\nscore=-0.004\nscore=-0.403\n</code></pre>"},{"location":"user-guide/advanced/#multiple-arrays-of-different-types","title":"Multiple arrays of different types","text":""},{"location":"user-guide/advanced/#window-types","title":"Window types","text":"<p>In time series forecasting we can use two different type of windows to split the data into training and testing while backtesting/cross-validating a model: rolling or expanding.</p> <p>A rolling window is a fixed-size window that slides over the data, while an expanding window starts with a minimum size and grows over time.</p> <p>The <code>window</code> parameter can be set to either <code>\"rolling\"</code> (or default) or <code>\"expanding\"</code> to choose the window type to use when splitting the data.</p> <p>Let's use the same dataset and configuration as before but with different window types.</p> <p></p> <p>As we can assess graphically, the only difference is the size of the training set, for the rolling window it has a fixed size (in terms of time periods) while the expanding window grows in size over time. On the other hand, the forecasting set is the same for both window types.</p> <p>Since working with different window types is quite common, we provide two classes that inherit from <code>TimeBasedSplit</code> and set the <code>window</code> parameter to <code>\"rolling\"</code> and <code>\"expanding\"</code> (respectively <code>RollingTimeSplit</code> and <code>ExpandingTimeSplit</code>).</p> Code to generate the plot <pre><code>import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nbase_config = {\n    \"frequency\": \"days\",\n    \"train_size\": 10,\n    \"forecast_horizon\": 5,\n    \"gap\": 1,\n    \"stride\": 3\n}\n\nwindow_types = [\"rolling\", \"expanding\"]\n\nfig = make_subplots(\n    rows=len(window_types),\n    cols=1,\n    subplot_titles=[f\"window='{w}'\" for w in window_types],\n    shared_xaxes=True,\n    vertical_spacing=0.1,\n    x_title=\"Time\",\n)\n\nfor _row, window in enumerate(window_types, start=1):\n\n    tbs = TimeBasedSplit(window=window, **base_config)\n\n    for _fold, (train_forecast, split_state) in enumerate(tbs.split(y/25, time_series=time_series, return_splitstate=True), start=1):\n\n        train, forecast = train_forecast\n\n        ts, te = split_state.train_start, split_state.train_end\n        fs, fe = split_state.forecast_start, split_state.forecast_end\n\n        fig.add_trace(\n            go.Scatter(\n                x=time_series[time_series.between(ts, te, inclusive=\"left\")],\n                y=train + _fold,\n                name=f\"Train Fold {_fold}\",\n                mode=\"markers\",\n                marker={\"color\": \"rgb(57, 105, 172)\"}\n            ),\n            row=_row,\n            col=1,\n        )\n\n        fig.add_trace(\n            go.Scatter(\n                x=time_series[time_series.between(fs, fe, inclusive=\"left\")],\n                y=forecast + _fold,\n                name=f\"Forecast Fold {_fold}\",\n                mode=\"markers\",\n                marker={\"color\": \"indianred\"}\n            ),\n            row=_row,\n            col=1,\n        )\n\nfig.update_layout(\n    showlegend=False,\n    height=1000,\n    **{\n        f\"yaxis{i}\": {\"autorange\": \"reversed\", \"title\": \"Fold\"}\n        for i in range(1, len(window_types)+1)\n    }\n)\n\nfig.show()\n</code></pre>"},{"location":"user-guide/advanced/#mode-types","title":"Mode types","text":"<p>There could be cases in which you want to generate the splits starting from the most recent observations and moving backwards in time. This is where the <code>mode</code> parameter comes in handy.</p> <p>The <code>mode</code> parameter can be set to either <code>\"forward\"</code> (our default) or <code>\"backward\"</code> to choose the direction in which the splits are moving.</p> <p>Let's use the same dataset and configuration as before but with different mode types.</p> <p></p> <p>As we wanted, the folds are generated in the opposite direction, starting from the most recent observations and moving backwards in time. However that's not the only difference between the two split sets.</p> <p>Since we want to guarantee that the train set is always at least of size <code>train_size</code>, the last few splits could end up with a smaller test set than the forecast horizon, in order to \"see\" every data point.</p> <p>On the other hand, for the backward mode, we also guarantee that the forecast set is always of size <code>forecast_horizon</code>, however, in the <code>window=\"rolling\"</code> case, this could mean that not every data point is seen (in the figure above, Jan 1<sup>st</sup> is never used in the training set).</p> <p>Therefore we end up with a different number of total splits, and this would hold true even in the case of <code>window=\"expanding\"</code> (in which however all the observation are used).</p> Code to generate the plot <pre><code>import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nbase_config = {\n    \"frequency\": \"days\",\n    \"train_size\": 10,\n    \"forecast_horizon\": 5,\n    \"gap\": 1,\n    \"stride\": 3\n}\n\nmode_types = [\"forward\", \"backward\"]\n\nfig = make_subplots(\n    rows=len(window_types),\n    cols=1,\n    subplot_titles=[f\"mode='{m}'\" for m in mode_types],\n    shared_xaxes=True,\n    vertical_spacing=0.1,\n    x_title=\"Time\",\n)\n\nfor _row, mode in enumerate(mode_types, start=1):\n\n    tbs = TimeBasedSplit(mode=mode, **base_config)\n\n    for _fold, (train_forecast, split_state) in enumerate(tbs.split(y/25, time_series=time_series, return_splitstate=True), start=1):\n\n        train, forecast = train_forecast\n\n        ts = split_state.train_start\n        te = split_state.train_end\n        fs = split_state.forecast_start\n        fe = split_state.forecast_end\n\n        fig.add_trace(\n            go.Scatter(\n                x=time_series[time_series.between(ts, te, inclusive=\"left\")],\n                y=train + _fold,\n                name=f\"Train Fold {_fold}\",\n                mode=\"markers\",\n                marker={\"color\": \"rgb(57, 105, 172)\"}\n            ),\n            row=_row,\n            col=1,\n        )\n\n        fig.add_trace(\n            go.Scatter(\n                x=time_series[time_series.between(fs, fe, inclusive=\"left\")],\n                y=forecast + _fold,\n                name=f\"Forecast Fold {_fold}\",\n                mode=\"markers\",\n                marker={\"color\": \"indianred\"}\n            ),\n            row=_row,\n            col=1,\n        )\n\nfig.update_layout(\n    showlegend=False,\n    height=1000,\n    **{\n        f\"yaxis{i}\": {\"autorange\": \"reversed\", \"title\": \"Fold\"}\n        for i in range(1, len(mode_types)+1)\n    }\n)\n\nfig.show()\n</code></pre>"},{"location":"user-guide/advanced/#take-n-splits","title":"Take n splits","text":"<p>The <code>mode=\"backward\"</code> could come in handy if one wants to take a fixed number of splits but guarantee to have the most recent observations in the test set.</p> <p>Currently this functionality is not directly supported by the <code>TimeBasedSplit</code> class, however it can be easily achieved by using <code>itertools.islice</code>. Let's see how:</p> <pre><code>from itertools import islice\n\ntake_n = 3\n\ntbs = TimeBasedSplit(\n    frequency=\"days\",\n    train_size=10,\n    forecast_horizon=5,\n    gap=1,\n    stride=3,\n    mode=\"backward\",\n)\n\nfor fold_number, (train, forecast) in islice(enumerate(tbs.split(y/25, time_series=time_series), start=1), take_n):\n    print(f\"Fold {fold_number}\")\n    print(f\"Train: {train.shape}, Forecast: {forecast.shape}\")\n</code></pre> <pre><code>Fold 1\nTrain: (124,), Forecast: (65,)\nFold 2\nTrain: (146,), Forecast: (68,)\nFold 3\nTrain: (126,), Forecast: (56,)\n</code></pre> <p></p> Code to generate the plot <pre><code>from itertools import islice\ntbs = TimeBasedSplit(mode=\"backward\", **base_config)\n\ntake_n = 3\nfig = go.Figure()\nfor _fold, (train_forecast, split_state) in islice(enumerate(tbs.split(y/25, time_series=time_series, return_splitstate=True), start=1), take_n):\n\n    train, forecast = train_forecast\n\n    ts = split_state.train_start\n    te = split_state.train_end\n    fs = split_state.forecast_start\n    fe = split_state.forecast_end\n\n    fig.add_trace(\n        go.Scatter(\n            x=time_series[time_series.between(ts, te, inclusive=\"left\")],\n            y=train + _fold,\n            name=f\"Train Fold {_fold}\",\n            mode=\"markers\",\n            marker={\"color\": \"rgb(57, 105, 172)\"}\n        )\n    )\n\n    fig.add_trace(\n        go.Scatter(\n            x=time_series[time_series.between(fs, fe, inclusive=\"left\")],\n            y=forecast + _fold,\n            name=f\"Forecast Fold {_fold}\",\n            mode=\"markers\",\n            marker={\"color\": \"indianred\"}\n        )\n    )\n\nfig.update_layout(\n    showlegend=False,\n    height=500,\n    **{\n        f\"yaxis{i}\": {\"autorange\": \"reversed\", \"title\": \"Fold\"}\n        for i in range(1, len(mode_types)+1)\n    }\n)\n\nfig.show()\n</code></pre>"},{"location":"user-guide/getting-started/","title":"Getting started \ud83d\udc0d","text":"<p>The following sections will guide you through the basic usage of the library.</p>"},{"location":"user-guide/getting-started/#timebasedsplit","title":"<code>TimeBasedSplit</code>","text":"<p>The <code>TimeBasedSplit</code> class allows to define a way to split your data based on time. There is a (long) list of parameters that can be set to define how to generate the splits. These allow for a lot of flexibility in how the data is split. Here is an overview of them:</p> <ul> <li><code>frequency</code>: we do not try to infer the frequency from the data, this information has to be specified beforehand. Available values are \"days\", \"seconds\", \"microseconds\", \"milliseconds\", \"minutes\", \"hours\", \"weeks\".</li> <li><code>train_size</code>: defines the minimum number of time units required to be in the train set, e.g. if <code>frequency=\"days\"</code> and <code>train_size=30</code>, the train set will have at least 30 days.</li> <li><code>forecast_horizon</code>: specifies the number of time units to forecast, e.g. if <code>frequency=\"days\"</code> and <code>forecast_horizon=7</code>, the forecast set will have 7 days. Notice that at the end of the time series, the forecast set might be smaller than the specified <code>forecast_horizon</code>.</li> <li><code>gap</code>: the number of time units to skip between the end of the train set and the start of the forecast set.</li> <li><code>stride</code>: how many time unit to move forward after each split. If <code>None</code>, the stride is equal to the <code>forecast_horizon</code>.</li> <li><code>window</code>: it can be either \"rolling\" or \"expanding\"</li> <li><code>mode</code>: it can be either \"forward\" or \"backward\" (generating splits either starting from the beginning or the end of the time series).</li> </ul> <p>Well that is a lot of parameters! But in our opinion it is what makes the library so flexible and powerful to be able to cover the large majority of use cases!</p> <p>Info</p> <p>As the list of so long, and it could be easy to provide values in the wrong order and/or be very hard to understand what each number means, we require to pass them as keyword only arguments!</p> Create a TimeBasedSplit instance<pre><code>from timebasedcv import TimeBasedSplit\n\ntbs = TimeBasedSplit(\n    frequency=\"days\",\n    train_size=10,\n    forecast_horizon=5,\n    gap=1,\n    stride=3\n)\n</code></pre> <p>Once an instance is created, it is possible to split a list of arrays using the <code>.split(...)</code> method, such method requires to pass a <code>time_series</code> as input to know how to split each array.</p> <p>Optionally it is possible to pass a <code>start_dt</code> and <code>end_dt</code> arguments as well. If provided, they are used in place of the <code>time_series.min()</code> and <code>time_series.max()</code> respectively to determine the period.</p> <p>This is useful because the series does not necessarely starts from the first date and/or terminates in the last date of the time period of interest, and it could lead to skewed splits.</p> <p>Info</p> <p>We made the opinionated choice of returning the sliced arrays from <code>.split(...)</code>, while scikit-learn CV Splitters return train and test indices of the split.</p> Generate the data<pre><code>import numpy as np\nimport pandas as pd\n\nRNG = np.random.default_rng(seed=42)\n\ndates = pd.Series(pd.date_range(\"2023-01-01\", \"2023-01-31\", freq=\"D\"))\nsize = len(dates)\n\ndf = (pd.concat([\n        pd.DataFrame({\n            \"time\": pd.date_range(start, end, periods=_size, inclusive=\"left\"),\n            \"a\": RNG.normal(size=_size-1),\n            \"b\": RNG.normal(size=_size-1),\n        })\n        for start, end, _size in zip(dates[:-1], dates[1:], RNG.integers(2, 24, size-1))\n    ])\n    .reset_index(drop=True)\n    .assign(y=lambda t: t[[\"a\", \"b\"]].sum(axis=1) + RNG.normal(size=t.shape[0])/25)\n)\n\ndf.set_index(\"time\").resample(\"D\").agg(count=(\"y\", np.size)).head(5)\n</code></pre> <pre><code>            count\ntime\n2023-01-01      2\n2023-01-02     18\n2023-01-03     15\n2023-01-04     10\n2023-01-05     10\n</code></pre> <p>Now let's run split the data with the provided <code>TimeBasedSplit</code> instance:</p> Generate the splits<pre><code>X, y, time_series = df.loc[:, [\"a\", \"b\"]], df[\"y\"], df[\"time\"]\n\nfor X_train, X_forecast, y_train, y_forecast in tbs.split(X, y, time_series=time_series):\n    print(f\"Train: {X_train.shape}, Forecast: {X_forecast.shape}\")\n</code></pre> <pre><code>Train: (100, 2), Forecast: (51, 2)\nTrain: (114, 2), Forecast: (50, 2)\n...\nTrain: (124, 2), Forecast: (40, 2)\nTrain: (137, 2), Forecast: (22, 2)\n</code></pre> <p>As we can see, each split does not necessarely have the same number of points, this is because the time series has a different number of points per day.</p> <p>Let's visualize the splits (blue dots represent the train points, while the red dots represent the forecastng points).</p> <p></p> Code to generate the plot <pre><code>import plotly.graph_objects as go\n\nfig = go.Figure()\n\nfor _fold, (train_forecast, split_state) in enumerate(\n    tbs.split(y/25, time_series=time_series, return_splitstate=True),\n    start=1,\n    ):\n\n    train, forecast = train_forecast\n\n    ts = split_state.train_start\n    te = split_state.train_end\n    fs = split_state.forecast_start\n    fe = split_state.forecast_end\n\n    fig.add_trace(\n        go.Scatter(\n            x=time_series[time_series.between(ts, te, inclusive=\"left\")],\n            y=train + _fold,\n            name=f\"Train Fold {_fold}\",\n            mode=\"markers\",\n            marker={\"color\": \"rgb(57, 105, 172)\"}\n        )\n    )\n\n    fig.add_trace(\n        go.Scatter(\n            x=time_series[time_series.between(fs, fe, inclusive=\"left\")],\n            y=forecast + _fold,\n            name=f\"Forecast Fold {_fold}\",\n            mode=\"markers\",\n            marker={\"color\": \"indianred\"}\n        )\n    )\n\n    fig.update_layout(\n        title={\n            \"text\": \"Time Based Cross Validation\",\n            \"y\":0.95, \"x\":0.5,\n            \"xanchor\": \"center\",\n            \"yanchor\": \"top\"\n        },\n        showlegend=True,\n        height=500,\n        yaxis = {\"autorange\": \"reversed\", \"title\": \"Fold\"}\n    )\n\nfig.show()\n</code></pre> <p>Here is an example of a few different configuration values for the splitter:</p> <p></p> Code to generate the plot <pre><code>import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nconfigs = [\n    {\n        \"frequency\": \"days\",\n        \"train_size\": 14,\n        \"forecast_horizon\": 7,\n        \"gap\": 2,\n        \"stride\": 5,\n        \"window\": \"expanding\"\n    },\n    {\n        \"frequency\": \"days\",\n        \"train_size\": 14,\n        \"forecast_horizon\": 7,\n        \"gap\": 2,\n        \"stride\": 5,\n        \"window\": \"rolling\"\n    },\n    {\n        \"frequency\": \"days\",\n        \"train_size\": 14,\n        \"forecast_horizon\": 7,\n        \"gap\": 0,\n        \"stride\": None,\n        \"window\": \"rolling\"\n    }\n]\n\nfig = make_subplots(\n    rows=len(configs),\n    cols=1,\n    subplot_titles=[str(config) for config in configs],\n    shared_xaxes=True,\n    vertical_spacing=0.1,\n    x_title=\"Time\",\n)\n\nfor _row, config in enumerate(configs, start=1):\n\n    tbs = TimeBasedSplit(**config)\n\n    for _fold, (train_forecast, split_state) in enumerate(tbs.split(y/25, time_series=time_series, return_splitstate=True), start=1):\n\n        train, forecast = train_forecast\n\n        ts = split_state.train_start\n        te = split_state.train_end\n        fs = split_state.forecast_start\n        fe = split_state.forecast_end\n\n        fig.add_trace(\n            go.Scatter(\n                x=time_series[time_series.between(ts, te, inclusive=\"left\")],\n                y=train + _fold,\n                name=f\"Train Fold {_fold}\",\n                mode=\"markers\",\n                marker={\"color\": \"rgb(57, 105, 172)\"}\n            ),\n            row=_row,\n            col=1,\n        )\n\n        fig.add_trace(\n            go.Scatter(\n                x=time_series[time_series.between(fs, fe, inclusive=\"left\")],\n                y=forecast + _fold,\n                name=f\"Forecast Fold {_fold}\",\n                mode=\"markers\",\n                marker={\"color\": \"indianred\"}\n            ),\n            row=_row,\n            col=1,\n        )\n\nfig.update_layout(\n    title={\n        \"text\": \"Time Based Cross Validation\",\n        \"y\":0.95, \"x\":0.5,\n        \"xanchor\": \"center\",\n        \"yanchor\": \"top\"\n    },\n    showlegend=False,\n    height=750,\n    **{\n        f\"yaxis{i}\": {\"autorange\": \"reversed\", \"title\": \"Fold\"}\n        for i in range(1, len(configs)+1)\n    }\n)\n\nfig.show()\n</code></pre>"},{"location":"user-guide/getting-started/#multiple-arrays","title":"Multiple arrays","text":"<p>It is possible to split multiple any arbitrary number of arrays at the same time, similarly to how train_test_split behaves.</p> Generate the splits<pre><code>time_series, a, b, y  = df.to_numpy().T\n\nfor a_train, a_test, b_train, b_test, y_train, y_test in tbs.split(a, b, y, time_series=time_series):\n    # Do some magic!\n</code></pre> <p>Info</p> <p>The only requirement is that the all the arrays must have the same length, as we use the mask on the <code>time_series</code> to slice each one of them.</p> <p>Warning</p> <p>Ideally each array can be a different type (numpy, pandas, polars, and so on...), in practice there are a few limitations that might arise from the different types, so please be aware of that.</p>"},{"location":"user-guide/scikit-learn/","title":"Scikit-learn component \ud83d\ude80","text":"<p>scikit-learn CV Splitters require a splitter to behave in a certain way:</p> <ul> <li><code>.split(...)</code> method should have the following signature: <code>.split(self, X, y, groups)</code>.</li> <li><code>.split(...)</code> method should return train and test indices of the split.</li> <li>know the total number of splits a priori, independently of <code>X, y, groups</code> arrays.</li> </ul> <p>Therefore, our <code>TimeBasedSplit</code> is not compatible with scikit-learn.</p>"},{"location":"user-guide/scikit-learn/#timebasedcvsplitter","title":"<code>TimeBasedCVSplitter</code>","text":"<p>Considering the above requirements, we provide a scikit-learn compatible splitter: <code>TimeBasedCVSplitter</code> in the sklearn module.</p> <pre><code>from timebasedcv.sklearn import TimeBasedCVSplitter\n</code></pre> <p>To be scikit-learn compatible, <code>TimeBasedCVSplitter</code> is initialized with the same parameters of <code>TimeBasedSplit</code> and the <code>time_series</code> containing the time information used to generate the train and test indices of each split.</p> <p>From a point of view, <code>TimeBasedCVSplitter</code> has all the features that <code>TimeBasedSplit</code> has, plus the compatibility with scikit-learn.</p> <p>This comes to the cost of requiring to know <code>time_series</code> beforehand, during <code>.__init__()</code> step. Therefore it is not possible to instantiate the split class once and re-use it with different time series dynamically.</p>"},{"location":"user-guide/scikit-learn/#example","title":"Example","text":"<p>In the following example we will see how to use it with a <code>Ridge</code> model and <code>RandomizedSearchCV</code> to find the best parameters for the model.</p> Imports<pre><code>import numpy as np\nimport pandas as pd\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom timebasedcv.sklearn import TimeBasedCVSplitter\n</code></pre> Generate the data<pre><code>RNG = np.random.default_rng(seed=42)\n\ndates = pd.Series(pd.date_range(\"2023-01-01\", \"2023-01-31\", freq=\"D\"))\nsize = len(dates)\n\ndf = (pd.concat([\n        pd.DataFrame({\n            \"time\": pd.date_range(start, end, periods=_size, inclusive=\"left\"),\n            \"a\": RNG.normal(size=_size-1),\n            \"b\": RNG.normal(size=_size-1),\n        })\n        for start, end, _size in zip(dates[:-1], dates[1:], RNG.integers(2, 24, size-1))\n    ])\n    .reset_index(drop=True)\n    .assign(y=lambda t: t[[\"a\", \"b\"]].sum(axis=1) + RNG.normal(size=t.shape[0])/25)\n)\n\ndf.set_index(\"time\").resample(\"D\").agg(count=(\"y\", np.size)).head(5)\n</code></pre> <pre><code>            count\ntime\n2023-01-01      1\n2023-01-02     10\n2023-01-03      9\n2023-01-04     14\n2023-01-05     20\n</code></pre> Run cross validation<pre><code>X, y, time_series = df.loc[:, [\"a\", \"b\"]], df[\"y\"], df[\"time\"]\n\ncv = TimeBasedCVSplitter(\n    frequency=\"days\",\n    train_size=10,\n    forecast_horizon=3,\n    gap=0,\n    stride=2,\n    window=\"rolling\",\n    time_series=time_series,  # (1)\n)\n\nparam_grid = {\n    \"alpha\": np.linspace(0.1, 2, 10),\n    \"fit_intercept\": [True, False],\n    \"positive\": [True, False],\n}\n\nrandom_search_cv = RandomizedSearchCV(\n    estimator=Ridge(),\n    param_distributions=param_grid,\n    cv=cv,\n    n_jobs=-1,\n).fit(X, y)\n\nrandom_search_cv.best_params_\n</code></pre> <ol> <li>Required in <code>.__init__()</code> method to generate the train and test indices of each split.</li> </ol> <pre><code>{'positive': False, 'fit_intercept': False, 'alpha': 0.522}\n</code></pre>"}]}